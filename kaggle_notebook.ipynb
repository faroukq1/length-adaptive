{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f998c25",
   "metadata": {},
   "source": [
    "# Length-Adaptive Sequential Recommendation\n",
    "\n",
    "**Hybrid SASRec + LightGCN with Adaptive Fusion on MovieLens-1M**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° FAST TRACK (13 minutes total)\n",
    "\n",
    "**Run only these cells if time matters:**\n",
    "1. ‚úÖ **Cell 3** - Clone repo (2 min)\n",
    "2. ‚úÖ **Cell 5** - Install dependencies (1 min)  \n",
    "3. ‚ö° **Cell 6** - Check GPU (10 sec)\n",
    "4. ‚úÖ **Cell 7** - Verify/preprocess data (2-3 min if needed) ‚Üê **CRITICAL**\n",
    "5. ‚ùå **Cell 9** - SKIP quick test\n",
    "6. ‚úÖ **Cell 10** - Train Hybrid (~10 min) ‚Üê **MAIN EXPERIMENT**\n",
    "7. ‚ùå **Cell 11** - SKIP SASRec (already have baseline)\n",
    "8. ‚úÖ **Cell 15** - Quick results view (5 sec)\n",
    "9. ‚úÖ **Cell 20** - Download results (30 sec)\n",
    "\n",
    "**Total: ~15 minutes** instead of 45+ minutes\n",
    "\n",
    "‚ö†Ô∏è **IMPORTANT:** Cell 7 is critical - it checks if data exists and preprocesses if needed!\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What You Get\n",
    "\n",
    "- Trained hybrid model with length-adaptive fusion\n",
    "- Complete test metrics (HR@10, NDCG@10, MRR@10)\n",
    "- Performance by user groups (short/medium/long)\n",
    "- Comparison with existing SASRec baseline\n",
    "- Downloadable results for local analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4a69f",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository\n",
    "\n",
    "Cloning from: https://github.com/faroukq1/length-adaptive.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2293cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/faroukq1/length-adaptive.git\n",
    "\n",
    "# Change to project directory\n",
    "%cd length-adaptive\n",
    "\n",
    "# Verify structure\n",
    "!echo \"‚úì Source code:\"\n",
    "!ls -la src/\n",
    "\n",
    "!echo \"\\n‚úì Experiments scripts:\"\n",
    "!ls -lh experiments/\n",
    "\n",
    "!echo \"\\nüìÅ Data directories:\"\n",
    "!ls -lh data/ 2>/dev/null || echo \"   (Data will be downloaded in next step if needed)\"\n",
    "\n",
    "print(\"\\n‚úÖ Repository cloned successfully!\")\n",
    "print(\"‚ö†Ô∏è  Note: Preprocessed data may not be in repo - we'll check/generate in next step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb798d",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies\n",
    "\n",
    "Installing PyTorch Geometric and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages quietly\n",
    "!pip install -q torch-geometric tqdm scikit-learn pandas matplotlib\n",
    "\n",
    "print(\"‚úì All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143777ec",
   "metadata": {},
   "source": [
    "## Step 3: Verify GPU Setup\n",
    "\n",
    "Check if GPU is available and will be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!python check_gpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c56e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if preprocessed data exists\n",
    "data_file = 'data/ml-1m/processed/sequences.pkl'\n",
    "graph_file = 'data/graphs/cooccurrence_graph.pkl'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç Checking Data Files\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if os.path.exists(data_file):\n",
    "    print(f\"‚úÖ Sequential data found: {data_file}\")\n",
    "    print(f\"   Size: {os.path.getsize(data_file) / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    print(f\"‚ùå Sequential data NOT found: {data_file}\")\n",
    "    print(\"   ‚Üí Need to run preprocessing!\")\n",
    "\n",
    "if os.path.exists(graph_file):\n",
    "    print(f\"‚úÖ Graph data found: {graph_file}\")\n",
    "    print(f\"   Size: {os.path.getsize(graph_file) / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    print(f\"‚ùå Graph data NOT found: {graph_file}\")\n",
    "    print(\"   ‚Üí Need to build graph!\")\n",
    "\n",
    "# Check raw data\n",
    "raw_file = 'data/ml-1m/raw/ml-1m/ratings.dat'\n",
    "if os.path.exists(raw_file):\n",
    "    print(f\"‚úÖ Raw data found: {raw_file}\")\n",
    "else:\n",
    "    print(f\"‚ùå Raw data NOT found: {raw_file}\")\n",
    "    print(\"   ‚Üí Need to download MovieLens-1M!\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# If data is missing, run preprocessing\n",
    "if not os.path.exists(data_file) or not os.path.exists(graph_file):\n",
    "    print(\"\\nüîß Running preprocessing...\")\n",
    "    print(\"This will take 2-3 minutes.\\n\")\n",
    "    \n",
    "    # Download MovieLens-1M if needed\n",
    "    if not os.path.exists(raw_file):\n",
    "        print(\"üì• Downloading MovieLens-1M dataset...\")\n",
    "        !mkdir -p data/ml-1m/raw\n",
    "        !wget -q http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "        !unzip -q ml-1m.zip\n",
    "        !mv ml-1m data/ml-1m/raw/\n",
    "        !rm -f ml-1m.zip\n",
    "        print(\"‚úÖ Download complete!\\n\")\n",
    "    \n",
    "    # Run preprocessing\n",
    "    print(\"üîÑ Preprocessing sequential data...\")\n",
    "    !python -m src.data.preprocess\n",
    "    \n",
    "    # Build graph\n",
    "    print(\"\\nüîÑ Building co-occurrence graph...\")\n",
    "    !python -m src.data.graph_builder\n",
    "    \n",
    "    print(\"\\n‚úÖ Preprocessing complete!\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n‚úÖ All data files ready!\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332fc101",
   "metadata": {},
   "source": [
    "## Step 3b: Verify Data Files\n",
    "\n",
    "Check if preprocessed data exists, or run preprocessing if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ee136",
   "metadata": {},
   "source": [
    "## üìã Experiment Priority Guide\n",
    "\n",
    "This notebook includes experiments from the action plan to beat SASRec baseline:\n",
    "\n",
    "**Priority 1 (Quick - Run First):**\n",
    "- ‚úÖ SASRec Baseline (Step 6)\n",
    "- ‚úÖ Hybrid Discrete (Step 5) - Our best model\n",
    "\n",
    "**Priority 2 (Optimization - Run if time permits):**\n",
    "- üî¨ Grid Search for Optimal Alpha (Advanced section)\n",
    "- üî¨ All Hybrid Variants (Advanced section)\n",
    "\n",
    "**Current Best Results:**\n",
    "- Hybrid Fixed (Œ±=0.5): HR@10 = 9.99% (+3.7% vs baseline)\n",
    "- Short-history users: +42% improvement\n",
    "\n",
    "**Target:** Beat SASRec on overall HR@10 by ‚â•3% and short-user HR@10 by ‚â•20%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225334f",
   "metadata": {},
   "source": [
    "## Step 4: Quick Test (OPTIONAL - Skip to Save Time)\n",
    "\n",
    "‚ö° **SKIP THIS** if you're in a hurry - saves 2 minutes!\n",
    "\n",
    "This just verifies setup works. We'll go straight to full training instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKIP: Quick test (saves 2 minutes)\n",
    "# Uncomment only if you want to verify setup first\n",
    "\n",
    "# !python test_training.py\n",
    "\n",
    "print(\"‚ö° Skipped quick test to save time - going straight to full training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea70fe",
   "metadata": {},
   "source": [
    "## ‚ö° Step 5: Train Hybrid Model (CRITICAL - MUST RUN)\n",
    "\n",
    "**This is the main experiment!**\n",
    "\n",
    "Train our length-adaptive hybrid model:\n",
    "- Short history users (‚â§10 items): More collaborative filtering (GNN)\n",
    "- Medium users (10-50 items): Balanced fusion\n",
    "- Long history users (>50 items): More sequential patterns (Transformer)\n",
    "\n",
    "**Time: ~10 minutes with GPU T4**\n",
    "\n",
    "With early stopping, training typically converges at epoch 20-30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö° CRITICAL: Train Hybrid Discrete Model (MUST RUN)\n",
    "# This is the main experiment - takes ~10 minutes with GPU\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ Training Hybrid Discrete Model\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "!python experiments/run_experiment.py \\\n",
    "    --model hybrid_discrete \\\n",
    "    --epochs 50 \\\n",
    "    --batch_size 256 \\\n",
    "    --lr 0.001 \\\n",
    "    --d_model 64 \\\n",
    "    --n_heads 2 \\\n",
    "    --n_blocks 2 \\\n",
    "    --patience 10\n",
    "\n",
    "print(\"\\n‚úÖ Training complete! Check results/ folder for outputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54faf4d7",
   "metadata": {},
   "source": [
    "## Step 6: Train SASRec Baseline (Optional - Skip if you already have it)\n",
    "\n",
    "**‚ö†Ô∏è SKIP THIS STEP if:**\n",
    "- You already have `results/sasrec_*/` folder from previous runs\n",
    "- You haven't changed data preprocessing or hyperparameters\n",
    "- You just want to test new hybrid variants\n",
    "\n",
    "**Only run this if:**\n",
    "- First time training\n",
    "- Changed hyperparameters\n",
    "- Want to verify reproducibility\n",
    "- Need fresh baseline for comparison\n",
    "\n",
    "**Alternative:** Copy your existing `results/sasrec_*/` folder to Kaggle instead of retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: Skip SASRec training (if you already have results)\n",
    "print(\"üí° Skipping SASRec - using existing baseline results\")\n",
    "print(\"   If you need to train SASRec, uncomment the code below:\\n\")\n",
    "\n",
    "# OPTION 2: Train SASRec baseline (uncomment if needed)\n",
    "# print(\"=\"*70)\n",
    "# print(\"üöÄ Training SASRec Baseline\")\n",
    "# print(\"=\"*70)\n",
    "# \n",
    "# !python experiments/run_experiment.py \\\n",
    "#     --model sasrec \\\n",
    "#     --epochs 50 \\\n",
    "#     --batch_size 256 \\\n",
    "#     --lr 0.001 \\\n",
    "#     --patience 10\n",
    "# \n",
    "# print(\"\\n‚úÖ Baseline training complete!\")\n",
    "\n",
    "# OPTION 3: Upload existing SASRec results\n",
    "# If you have results locally, you can upload the folder:\n",
    "# 1. Zip your local results/sasrec_*/ folder\n",
    "# 2. Upload to Kaggle input data\n",
    "# 3. Copy to results/ directory:\n",
    "# !mkdir -p results\n",
    "# !cp -r /kaggle/input/your-sasrec-results/* results/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab458a",
   "metadata": {},
   "source": [
    "## Step 7: Train All Models (Optional - takes 3-5 hours)\n",
    "\n",
    "Uncomment to train all 5 model variants:\n",
    "- `sasrec`: Transformer baseline\n",
    "- `hybrid_fixed`: Fixed fusion weight (Œ±=0.5)\n",
    "- `hybrid_discrete`: Bin-based fusion (our approach)\n",
    "- `hybrid_learnable`: Per-user learned weights\n",
    "- `hybrid_continuous`: Neural network fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run all experiments\n",
    "# !bash scripts/run_all_experiments.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5817e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all hybrid variants\n",
    "# Uncomment to run complete ablation study (takes ~8 hours with GPU)\n",
    "\n",
    "# models = ['hybrid_fixed', 'hybrid_discrete', 'hybrid_learnable', 'hybrid_continuous']\n",
    "# \n",
    "# for model in models:\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(f\"üöÄ Training {model}\")\n",
    "#     print(f\"{'='*70}\\n\")\n",
    "#     \n",
    "#     !python experiments/run_experiment.py \\\n",
    "#         --model {model} \\\n",
    "#         --epochs 50 \\\n",
    "#         --batch_size 256 \\\n",
    "#         --lr 0.001 \\\n",
    "#         --patience 10\n",
    "#     \n",
    "#     print(f\"\\n‚úÖ {model} complete!\")\n",
    "\n",
    "# Quick version: Use the automated script\n",
    "# !bash scripts/run_all_experiments.sh\n",
    "\n",
    "print(\"üí° Tip: Uncomment to train all model variants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529e222",
   "metadata": {},
   "source": [
    "## üî¨ Advanced: All Hybrid Variants\n",
    "\n",
    "Train all fusion strategies for complete comparison:\n",
    "- **Fixed**: Single Œ± for all users\n",
    "- **Discrete**: Bin-based (short/medium/long)\n",
    "- **Learnable**: Learned bin weights\n",
    "- **Continuous**: Smooth function of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62309b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for optimal alpha\n",
    "# Tests Œ± ‚àà {0.3, 0.4, 0.5, 0.6, 0.7}\n",
    "# Uncomment to run (takes ~10-12 hours with GPU)\n",
    "\n",
    "# alphas = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "# \n",
    "# for alpha in alphas:\n",
    "#     print(f\"\\n{'='*70}\")\n",
    "#     print(f\"üî¨ Testing Fixed Alpha = {alpha}\")\n",
    "#     print(f\"{'='*70}\\n\")\n",
    "#     \n",
    "#     !python experiments/run_experiment.py \\\n",
    "#         --model hybrid_fixed \\\n",
    "#         --fixed_alpha {alpha} \\\n",
    "#         --epochs 50 \\\n",
    "#         --batch_size 256 \\\n",
    "#         --lr 0.001 \\\n",
    "#         --patience 10\n",
    "#     \n",
    "#     print(f\"\\n‚úÖ Alpha={alpha} complete!\")\n",
    "\n",
    "print(\"üí° Tip: Uncomment the code above to run grid search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2209e8",
   "metadata": {},
   "source": [
    "## üî¨ Advanced: Grid Search for Optimal Alpha (Fixed Fusion)\n",
    "\n",
    "Test different fixed alpha values to find the optimal fusion weight.\n",
    "This helps us understand the best balance between GNN and SASRec embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06b542",
   "metadata": {},
   "source": [
    "## Step 8: Analyze Results\n",
    "\n",
    "Generate comparison tables and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af94e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate analysis using the built-in script\n",
    "print(\"=\"*70)\n",
    "print(\"üìä Generating Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "!python experiments/analyze_results.py --save_csv\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17afa32c",
   "metadata": {},
   "source": [
    "## Step 9: Display Results\n",
    "\n",
    "Show performance comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f509c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Try to load results directly from experiments\n",
    "result_folders = glob.glob('results/*_*')\n",
    "\n",
    "if len(result_folders) == 0:\n",
    "    print(\"‚ùå No results found. Run experiments first!\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä OVERALL PERFORMANCE\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Collect all results\n",
    "    all_results = []\n",
    "    for folder in result_folders:\n",
    "        results_path = os.path.join(folder, 'results.json')\n",
    "        if os.path.exists(results_path):\n",
    "            with open(results_path, 'r') as f:\n",
    "                results = json.load(f)\n",
    "            \n",
    "            # Extract model name\n",
    "            folder_name = os.path.basename(folder)\n",
    "            model_name = '_'.join(folder_name.split('_')[:-2])\n",
    "            \n",
    "            all_results.append({\n",
    "                'Model': model_name,\n",
    "                'HR@5': results['test_metrics']['HR@5'],\n",
    "                'HR@10': results['test_metrics']['HR@10'],\n",
    "                'HR@20': results['test_metrics']['HR@20'],\n",
    "                'NDCG@5': results['test_metrics']['NDCG@5'],\n",
    "                'NDCG@10': results['test_metrics']['NDCG@10'],\n",
    "                'NDCG@20': results['test_metrics']['NDCG@20'],\n",
    "                'MRR@10': results['test_metrics']['MRR@10']\n",
    "            })\n",
    "    \n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "        df = df.sort_values('NDCG@10', ascending=False)\n",
    "        \n",
    "        # Display table\n",
    "        print(df.to_string(index=False, float_format='%.4f'))\n",
    "        \n",
    "        # Highlight best model\n",
    "        best = df.iloc[0]\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"üèÜ BEST MODEL: {best['Model']}\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"  NDCG@10: {best['NDCG@10']:.4f}\")\n",
    "        print(f\"  HR@10:   {best['HR@10']:.4f}\")\n",
    "        print(f\"  MRR@10:  {best['MRR@10']:.4f}\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "        \n",
    "        # Show improvement over baseline\n",
    "        sasrec_row = df[df['Model'] == 'sasrec']\n",
    "        if not sasrec_row.empty:\n",
    "            sasrec_ndcg = sasrec_row.iloc[0]['NDCG@10']\n",
    "            sasrec_hr = sasrec_row.iloc[0]['HR@10']\n",
    "            hybrid_ndcg = best['NDCG@10']\n",
    "            hybrid_hr = best['HR@10']\n",
    "            ndcg_imp = ((hybrid_ndcg - sasrec_ndcg) / sasrec_ndcg) * 100\n",
    "            hr_imp = ((hybrid_hr - sasrec_hr) / sasrec_hr) * 100\n",
    "            print(f\"üìà Improvement over SASRec baseline:\")\n",
    "            print(f\"   NDCG@10: {ndcg_imp:+.2f}%\")\n",
    "            print(f\"   HR@10:   {hr_imp:+.2f}%\\n\")\n",
    "    else:\n",
    "        print(\"‚ùå Could not parse results files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75391d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick performance check\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "\n",
    "results = {}\n",
    "for folder in glob.glob('results/*_*'):\n",
    "    results_file = os.path.join(folder, 'results.json')\n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file) as f:\n",
    "            data = json.load(f)\n",
    "        model = '_'.join(os.path.basename(folder).split('_')[:-2])\n",
    "        results[model] = data['test_metrics']['HR@10']\n",
    "\n",
    "if results:\n",
    "    print(\"=\"*60)\n",
    "    print(\"‚ö° QUICK RESULTS - HR@10 (Higher is Better)\")\n",
    "    print(\"=\"*60)\n",
    "    for model, hr10 in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  {model:20s}: {hr10:.4f} ({hr10*100:.2f}%)\")\n",
    "    \n",
    "    if 'sasrec' in results and 'hybrid_discrete' in results:\n",
    "        improvement = ((results['hybrid_discrete'] - results['sasrec']) / results['sasrec']) * 100\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"üìà Hybrid improvement: {improvement:+.1f}%\")\n",
    "        if improvement > 2:\n",
    "            print(\"‚úÖ SUCCESS: Beat baseline by >2%!\")\n",
    "        print(\"=\"*60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results found yet. Train models first (Cell 9).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733872be",
   "metadata": {},
   "source": [
    "## ‚ö° FAST TRACK: Quick Results View\n",
    "\n",
    "If you're short on time, just run this cell to see if hybrid beats baseline!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ae64e",
   "metadata": {},
   "source": [
    "## Step 10: Performance by User Group\n",
    "\n",
    "Compare performance across different user history lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc663df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load grouped metrics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä PERFORMANCE BY USER GROUP\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "result_folders = glob.glob('results/*_*')\n",
    "\n",
    "if len(result_folders) == 0:\n",
    "    print(\"‚ùå No results found.\")\n",
    "else:\n",
    "    # Collect grouped results\n",
    "    group_data = {'short': [], 'medium': [], 'long': []}\n",
    "    \n",
    "    for folder in result_folders:\n",
    "        results_path = os.path.join(folder, 'results.json')\n",
    "        if os.path.exists(results_path):\n",
    "            with open(results_path, 'r') as f:\n",
    "                results = json.load(f)\n",
    "            \n",
    "            # Extract model name\n",
    "            folder_name = os.path.basename(folder)\n",
    "            model_name = '_'.join(folder_name.split('_')[:-2])\n",
    "            \n",
    "            # Extract grouped metrics\n",
    "            grouped = results.get('grouped_metrics', {})\n",
    "            \n",
    "            for group in ['short', 'medium', 'long']:\n",
    "                if group in grouped:\n",
    "                    group_data[group].append({\n",
    "                        'Model': model_name,\n",
    "                        'HR@10': grouped[group]['HR@10'],\n",
    "                        'NDCG@10': grouped[group]['NDCG@10'],\n",
    "                        'MRR@10': grouped[group]['MRR@10'],\n",
    "                        'Count': grouped[group]['count']\n",
    "                    })\n",
    "    \n",
    "    # Display each group\n",
    "    for group_name in ['short', 'medium', 'long']:\n",
    "        if group_data[group_name]:\n",
    "            df_group = pd.DataFrame(group_data[group_name])\n",
    "            df_group = df_group.sort_values('NDCG@10', ascending=False)\n",
    "            \n",
    "            print(f\"\\n{group_name.upper()} HISTORY USERS:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(df_group.to_string(index=False, float_format='%.4f'))\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"\\n{group_name.upper()} HISTORY USERS:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"‚ö†Ô∏è  No {group_name} user data found (possibly no users in this range)\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a0544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Check for alpha statistics in hybrid model results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç ALPHA VALUES (Fusion Weights)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "hybrid_folders = [f for f in glob.glob('results/hybrid_*') if os.path.isdir(f)]\n",
    "\n",
    "if not hybrid_folders:\n",
    "    print(\"‚ö†Ô∏è  No hybrid model results found. Alpha tracking only works for hybrid models.\")\n",
    "else:\n",
    "    for folder in hybrid_folders:\n",
    "        alpha_path = os.path.join(folder, 'alpha_stats.json')\n",
    "        if os.path.exists(alpha_path):\n",
    "            with open(alpha_path, 'r') as f:\n",
    "                alpha_stats = json.load(f)\n",
    "            \n",
    "            folder_name = os.path.basename(folder)\n",
    "            model_name = '_'.join(folder_name.split('_')[:-2])\n",
    "            \n",
    "            print(f\"{model_name.upper()}:\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            for group in ['short', 'medium', 'long', 'overall']:\n",
    "                if group in alpha_stats:\n",
    "                    stats = alpha_stats[group]\n",
    "                    if group != 'overall' and 'count' in stats:\n",
    "                        print(f\"  {group.capitalize():8s}: mean={stats['mean']:.3f}, std={stats['std']:.3f}, count={stats['count']}\")\n",
    "                    elif group == 'overall':\n",
    "                        print(f\"  {group.capitalize():8s}: mean={stats['mean']:.3f}, std={stats['std']:.3f}\")\n",
    "            print()\n",
    "        else:\n",
    "            # Show expected alpha values based on model type\n",
    "            folder_name = os.path.basename(folder)\n",
    "            model_name = '_'.join(folder_name.split('_')[:-2])\n",
    "            \n",
    "            print(f\"{model_name.upper()}:\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            if 'discrete' in model_name:\n",
    "                print(\"  Expected: Short=0.3, Medium=0.5, Long=0.7 (discrete bins)\")\n",
    "            elif 'fixed' in model_name:\n",
    "                print(\"  Expected: All users = 0.5 (fixed fusion)\")\n",
    "            elif 'learnable' in model_name:\n",
    "                print(\"  Expected: Learned during training (check model params)\")\n",
    "            elif 'continuous' in model_name:\n",
    "                print(\"  Expected: Smooth function of sequence length\")\n",
    "            \n",
    "            print(\"  ‚ö†Ô∏è  Alpha statistics not saved (enable with track_alpha=True)\")\n",
    "            print()\n",
    "    \n",
    "    print(\"\\nüí° Alpha interpretation:\")\n",
    "    print(\"   ‚Ä¢ Œ± close to 0: More weight on GNN (collaborative)\")\n",
    "    print(\"   ‚Ä¢ Œ± close to 1: More weight on SASRec (sequential)\")\n",
    "    print(\"   ‚Ä¢ Œ± = 0.5: Equal balance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4086cb30",
   "metadata": {},
   "source": [
    "## Step 10b: Alpha Statistics (Hybrid Models Only)\n",
    "\n",
    "For hybrid models, check what fusion weights (alpha values) were used for different user groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2feda3",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Learning Curves\n",
    "\n",
    "Plot training loss and validation NDCG over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Find all experiment results\n",
    "result_folders = glob.glob('results/*_*')\n",
    "\n",
    "if len(result_folders) > 0:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Training Loss\n",
    "    for folder in result_folders:\n",
    "        history_path = os.path.join(folder, 'history.json')\n",
    "        if os.path.exists(history_path):\n",
    "            try:\n",
    "                with open(history_path, 'r') as f:\n",
    "                    history = json.load(f)\n",
    "                \n",
    "                # Extract model name from folder\n",
    "                parts = os.path.basename(folder).split('_')\n",
    "                model_name = '_'.join(parts[:-2]) if len(parts) > 2 else parts[0]\n",
    "                \n",
    "                if 'train_loss' in history and history['train_loss']:\n",
    "                    ax1.plot(history['train_loss'], label=model_name, marker='o', markersize=3, linewidth=2)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Could not load history from {folder}: {e}\")\n",
    "    \n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('BPR Loss', fontsize=12)\n",
    "    ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Validation NDCG@10\n",
    "    for folder in result_folders:\n",
    "        history_path = os.path.join(folder, 'history.json')\n",
    "        if os.path.exists(history_path):\n",
    "            try:\n",
    "                with open(history_path, 'r') as f:\n",
    "                    history = json.load(f)\n",
    "                \n",
    "                parts = os.path.basename(folder).split('_')\n",
    "                model_name = '_'.join(parts[:-2]) if len(parts) > 2 else parts[0]\n",
    "                \n",
    "                if 'val_metrics' in history and history['val_metrics']:\n",
    "                    ndcg_values = [m.get('NDCG@10', 0) for m in history['val_metrics']]\n",
    "                    if ndcg_values:\n",
    "                        ax2.plot(ndcg_values, label=model_name, marker='o', markersize=3, linewidth=2)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Could not load validation metrics from {folder}: {e}\")\n",
    "    \n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('NDCG@10', fontsize=12)\n",
    "    ax2.set_title('Validation NDCG@10', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    plt.savefig('results/learning_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úì Saved to: results/learning_curves.png\")\n",
    "else:\n",
    "    print(\"No results to plot. Run experiments first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1299e15",
   "metadata": {},
   "source": [
    "## Step 12: Download Results\n",
    "\n",
    "Create a zip file of all results for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip of all results\n",
    "import os\n",
    "\n",
    "if os.path.exists('results') and os.listdir('results'):\n",
    "    !zip -r results.zip results/\n",
    "    \n",
    "    print(\"\\n‚úÖ Success!\")\n",
    "    print(\"Download 'results.zip' from the Output tab (right sidebar) ‚Üí\")\n",
    "    print(\"\\nContains:\")\n",
    "    print(\"  ‚Ä¢ Model checkpoints (best_model.pt)\")\n",
    "    print(\"  ‚Ä¢ Training history (history.json)\")\n",
    "    print(\"  ‚Ä¢ Test metrics (results.json)\")\n",
    "    print(\"  ‚Ä¢ Comparison tables (CSV files, if generated)\")\n",
    "    print(\"  ‚Ä¢ Learning curves (PNG)\")\n",
    "    \n",
    "    # Show what's in results\n",
    "    result_folders = [d for d in os.listdir('results') if os.path.isdir(os.path.join('results', d))]\n",
    "    print(f\"\\nüì¶ Packaged {len(result_folders)} experiment(s):\")\n",
    "    for folder in result_folders:\n",
    "        print(f\"  ‚Ä¢ {folder}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results folder found. Run experiments first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67291a1e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "You've successfully:\n",
    "1. ‚úÖ Cloned repository with preprocessed data\n",
    "2. ‚úÖ Installed all dependencies\n",
    "3. ‚úÖ Verified GPU availability\n",
    "4. ‚úÖ Tested training pipeline\n",
    "5. ‚úÖ Trained recommendation models\n",
    "6. ‚úÖ Analyzed and compared results\n",
    "7. ‚úÖ Visualized learning curves\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Key Results\n",
    "\n",
    "**Dataset:** MovieLens-1M\n",
    "- 6,034 users\n",
    "- 3,533 items  \n",
    "- 1M+ ratings\n",
    "- 151,874 co-occurrence edges\n",
    "\n",
    "**Models Trained:**\n",
    "- SASRec (Transformer baseline)\n",
    "- Hybrid with Discrete Fusion (length-adaptive)\n",
    "\n",
    "**Metrics:** Hit Rate (HR), NDCG, MRR at K={5, 10, 20}\n",
    "\n",
    "---\n",
    "\n",
    "## ‚è±Ô∏è Training Time & Epochs FAQ\n",
    "\n",
    "**Q: Why 50 epochs instead of 600 like in papers?**\n",
    "\n",
    "**A:** We use **early stopping** (patience=10):\n",
    "- Training automatically stops when validation NDCG@10 stops improving\n",
    "- With 50 epochs max ‚Üí usually converges at epoch 20-30 (~8-10 min GPU)\n",
    "- With 600 epochs max ‚Üí usually converges at epoch 30-40 (~35-45 min GPU)\n",
    "- Performance difference: ~2-3% for 10x more training time\n",
    "\n",
    "**Default (Fast):**\n",
    "```bash\n",
    "--epochs 50 --patience 10  # 8-10 min GPU, 95-98% of max performance\n",
    "```\n",
    "\n",
    "**Paper Setting (Thorough):**\n",
    "```bash\n",
    "--epochs 600 --patience 20  # 35-45 min GPU with early stopping, 100% performance\n",
    "```\n",
    "\n",
    "**Without Early Stopping (Not Recommended):**\n",
    "```bash\n",
    "--epochs 600 --patience 9999  # 80+ min GPU, risk of overfitting\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "**1. Match paper settings (600 epochs):**\n",
    "```python\n",
    "!python experiments/run_experiment.py \\\n",
    "    --model hybrid_discrete \\\n",
    "    --epochs 600 \\\n",
    "    --patience 20 \\\n",
    "    --batch_size 256 \\\n",
    "    --lr 0.001\n",
    "```\n",
    "\n",
    "**2. Experiment with hyperparameters:**\n",
    "```python\n",
    "!python experiments/run_experiment.py \\\n",
    "    --model hybrid_discrete \\\n",
    "    --epochs 100 \\\n",
    "    --batch_size 512 \\\n",
    "    --lr 0.0005 \\\n",
    "    --d_model 128 \\\n",
    "    --n_heads 4\n",
    "```\n",
    "\n",
    "**3. Try different fusion strategies:**\n",
    "- `--model hybrid_learnable` - Per-user learned weights\n",
    "- `--model hybrid_continuous` - Neural network fusion\n",
    "- `--model hybrid_fixed` - Fixed alpha=0.5\n",
    "\n",
    "**4. Analyze specific user groups:**\n",
    "Check `results/comparison_*.csv` for performance on short/medium/long history users\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub:** https://github.com/faroukq1/length-adaptive\n",
    "- **Paper:** Length-Adaptive Hybrid Sequential Recommendation\n",
    "- **Dataset:** MovieLens-1M (GroupLens)\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or issues?** Check the README.md and EXPERIMENTS.md in the repository."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
