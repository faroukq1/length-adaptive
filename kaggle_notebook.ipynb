{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f998c25",
   "metadata": {},
   "source": [
    "# Length-Adaptive Sequential Recommendation\n",
    "\n",
    "**Hybrid SASRec + LightGCN with Adaptive Fusion on MovieLens-1M**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Quick Start\n",
    "\n",
    "This notebook is ready to run! Just:\n",
    "1. **Enable GPU** (recommended): Settings â†’ Accelerator â†’ GPU T4\n",
    "2. **Click \"Run All\"** or run cells sequentially\n",
    "\n",
    "**Expected Time:**\n",
    "- With GPU T4: ~8-10 minutes per model\n",
    "- With CPU: ~40-50 minutes per model\n",
    "\n",
    "All data is already preprocessed and included in the repository!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f4a69f",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository\n",
    "\n",
    "Cloning from: https://github.com/faroukq1/length-adaptive.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2293cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository with all preprocessed data\n",
    "!git clone https://github.com/faroukq1/length-adaptive.git\n",
    "\n",
    "# Change to project directory\n",
    "%cd length-adaptive\n",
    "\n",
    "# Verify structure\n",
    "!echo \"âœ“ Source code:\"\n",
    "!ls -la src/\n",
    "\n",
    "!echo \"\\nâœ“ Preprocessed data:\"\n",
    "!ls -lh data/ml-1m/processed/\n",
    "\n",
    "!echo \"\\nâœ“ Co-occurrence graph:\"\n",
    "!ls -lh data/graphs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb798d",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies\n",
    "\n",
    "Installing PyTorch Geometric and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages quietly\n",
    "!pip install -q torch-geometric tqdm scikit-learn pandas matplotlib\n",
    "\n",
    "print(\"âœ“ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143777ec",
   "metadata": {},
   "source": [
    "## Step 3: Verify GPU Setup\n",
    "\n",
    "Check if GPU is available and will be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!python check_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225334f",
   "metadata": {},
   "source": [
    "## Step 4: Quick Test (2 epochs)\n",
    "\n",
    "Verify everything works with a quick 2-epoch test on both SASRec and Hybrid models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run quick training test\n",
    "!python test_training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea70fe",
   "metadata": {},
   "source": [
    "## Step 5: Train Hybrid Model (50 epochs)\n",
    "\n",
    "Train our best model: **Hybrid with Discrete Fusion**\n",
    "\n",
    "This model adapts based on user history length:\n",
    "- Short history users (â‰¤10 items): More collaborative filtering (GNN)\n",
    "- Medium users (10-50 items): Balanced fusion\n",
    "- Long history users (>50 items): More sequential patterns (Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edbea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Hybrid model with discrete fusion\n",
    "!python experiments/run_experiment.py \\\n",
    "    --model hybrid_discrete \\\n",
    "    --epochs 50 \\\n",
    "    --batch_size 256 \\\n",
    "    --lr 0.001 \\\n",
    "    --d_model 64 \\\n",
    "    --n_heads 2 \\\n",
    "    --n_blocks 2 \\\n",
    "    --patience 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54faf4d7",
   "metadata": {},
   "source": [
    "## Step 6: Train SASRec Baseline (Optional)\n",
    "\n",
    "Train baseline model for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee3a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SASRec baseline\n",
    "!python experiments/run_experiment.py \\\n",
    "    --model sasrec \\\n",
    "    --epochs 50 \\\n",
    "    --batch_size 256 \\\n",
    "    --lr 0.001 \\\n",
    "    --patience 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab458a",
   "metadata": {},
   "source": [
    "## Step 7: Train All Models (Optional - takes 3-5 hours)\n",
    "\n",
    "Uncomment to train all 5 model variants:\n",
    "- `sasrec`: Transformer baseline\n",
    "- `hybrid_fixed`: Fixed fusion weight (Î±=0.5)\n",
    "- `hybrid_discrete`: Bin-based fusion (our approach)\n",
    "- `hybrid_learnable`: Per-user learned weights\n",
    "- `hybrid_continuous`: Neural network fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run all experiments\n",
    "# !bash scripts/run_all_experiments.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06b542",
   "metadata": {},
   "source": [
    "## Step 8: Analyze Results\n",
    "\n",
    "Generate comparison tables and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af94e772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate analysis\n",
    "!python experiments/analyze_results.py --save_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17afa32c",
   "metadata": {},
   "source": [
    "## Step 9: Display Results\n",
    "\n",
    "Show performance comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f509c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load overall comparison\n",
    "if os.path.exists('results/overall_comparison.csv'):\n",
    "    df = pd.read_csv('results/overall_comparison.csv')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š OVERALL PERFORMANCE\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Highlight best model\n",
    "    best = df.iloc[0]\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"ðŸ† BEST MODEL: {best['Model']}\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"  NDCG@10: {best['NDCG@10']:.4f}\")\n",
    "    print(f\"  HR@10:   {best['HR@10']:.4f}\")\n",
    "    print(f\"  MRR@10:  {best['MRR@10']:.4f}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Show improvement over baseline\n",
    "    sasrec_row = df[df['Model'] == 'sasrec']\n",
    "    if not sasrec_row.empty:\n",
    "        sasrec_ndcg = sasrec_row.iloc[0]['NDCG@10']\n",
    "        hybrid_ndcg = best['NDCG@10']\n",
    "        improvement = ((hybrid_ndcg - sasrec_ndcg) / sasrec_ndcg) * 100\n",
    "        print(f\"ðŸ“ˆ Improvement over SASRec baseline: {improvement:+.2f}%\\n\")\n",
    "else:\n",
    "    print(\"âŒ No results found. Run experiments first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ae64e",
   "metadata": {},
   "source": [
    "## Step 10: Performance by User Group\n",
    "\n",
    "Compare performance across different user history lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc663df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Load grouped metrics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š PERFORMANCE BY USER GROUP\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "groups = ['short', 'medium', 'long']\n",
    "group_files = {\n",
    "    'short': 'results/comparison_short.csv',\n",
    "    'medium': 'results/comparison_medium.csv',\n",
    "    'long': 'results/comparison_long.csv'\n",
    "}\n",
    "\n",
    "for group_name, filepath in group_files.items():\n",
    "    if os.path.exists(filepath):\n",
    "        df_group = pd.read_csv(filepath)\n",
    "        print(f\"\\n{group_name.upper()} HISTORY USERS:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(df_group.to_string(index=False))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2feda3",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Learning Curves\n",
    "\n",
    "Plot training loss and validation NDCG over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find all experiment results\n",
    "result_folders = glob.glob('results/*_*')\n",
    "\n",
    "if len(result_folders) > 0:\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Training Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for folder in result_folders:\n",
    "        history_path = os.path.join(folder, 'history.json')\n",
    "        if os.path.exists(history_path):\n",
    "            with open(history_path, 'r') as f:\n",
    "                history = json.load(f)\n",
    "            \n",
    "            # Extract model name from folder\n",
    "            parts = os.path.basename(folder).split('_')\n",
    "            model_name = '_'.join(parts[:-2]) if len(parts) > 2 else parts[0]\n",
    "            \n",
    "            plt.plot(history['train_loss'], label=model_name, marker='o', markersize=3, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('BPR Loss', fontsize=12)\n",
    "    plt.title('Training Loss', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Validation NDCG@10\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for folder in result_folders:\n",
    "        history_path = os.path.join(folder, 'history.json')\n",
    "        if os.path.exists(history_path):\n",
    "            with open(history_path, 'r') as f:\n",
    "                history = json.load(f)\n",
    "            \n",
    "            parts = os.path.basename(folder).split('_')\n",
    "            model_name = '_'.join(parts[:-2]) if len(parts) > 2 else parts[0]\n",
    "            \n",
    "            ndcg_values = [m['ndcg@10'] for m in history['val_metrics']]\n",
    "            plt.plot(ndcg_values, label=model_name, marker='o', markersize=3, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('NDCG@10', fontsize=12)\n",
    "    plt.title('Validation NDCG@10', fontsize=14, fontweight='bold')\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/learning_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ“ Saved to: results/learning_curves.png\")\n",
    "else:\n",
    "    print(\"No results to plot. Run experiments first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1299e15",
   "metadata": {},
   "source": [
    "## Step 12: Download Results\n",
    "\n",
    "Create a zip file of all results for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip of all results\n",
    "!zip -r results.zip results/\n",
    "\n",
    "print(\"\\nâœ… Success!\")\n",
    "print(\"Download 'results.zip' from the Output tab (right sidebar) â†’\")\n",
    "print(\"\\nContains:\")\n",
    "print(\"  â€¢ Model checkpoints (best_model.pt)\")\n",
    "print(\"  â€¢ Training history (history.json)\")\n",
    "print(\"  â€¢ Test metrics (results.json)\")\n",
    "print(\"  â€¢ Comparison tables (CSV files)\")\n",
    "print(\"  â€¢ Learning curves (PNG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67291a1e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Summary\n",
    "\n",
    "You've successfully:\n",
    "1. âœ… Cloned repository with preprocessed data\n",
    "2. âœ… Installed all dependencies\n",
    "3. âœ… Tested training pipeline\n",
    "4. âœ… Trained recommendation models\n",
    "5. âœ… Analyzed and compared results\n",
    "6. âœ… Visualized learning curves\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¬ Key Results\n",
    "\n",
    "**Dataset:** MovieLens-1M\n",
    "- 6,034 users\n",
    "- 3,533 items  \n",
    "- 1M+ ratings\n",
    "- 74,170 co-occurrence edges\n",
    "\n",
    "**Models Trained:**\n",
    "- SASRec (Transformer baseline)\n",
    "- Hybrid with Discrete Fusion (length-adaptive)\n",
    "\n",
    "**Metrics:** Hit Rate (HR), NDCG, MRR at K={5, 10, 20}\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "**Experiment with hyperparameters:**\n",
    "```python\n",
    "!python experiments/run_experiment.py \\\n",
    "    --model hybrid_discrete \\\n",
    "    --epochs 100 \\\n",
    "    --batch_size 512 \\\n",
    "    --lr 0.0005 \\\n",
    "    --d_model 128 \\\n",
    "    --n_heads 4\n",
    "```\n",
    "\n",
    "**Try different fusion strategies:**\n",
    "- `--model hybrid_learnable` - Per-user learned weights\n",
    "- `--model hybrid_continuous` - Neural network fusion\n",
    "\n",
    "**Analyze specific user groups:**\n",
    "Check `results/comparison_*.csv` for performance on short/medium/long history users\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Resources\n",
    "\n",
    "- **GitHub:** https://github.com/faroukq1/length-adaptive\n",
    "- **Paper:** Length-Adaptive Hybrid Sequential Recommendation\n",
    "- **Dataset:** MovieLens-1M (GroupLens)\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or issues?** Check the README.md and EXPERIMENTS.md in the repository."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
