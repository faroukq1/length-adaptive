{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec64a38",
   "metadata": {},
   "source": [
    "# BERT4Rec + GNN Hybrid Experiments\n",
    "\n",
    "**Bidirectional Transformer with Graph Neural Network Fusion**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Experiment Goal\n",
    "\n",
    "This notebook compares **BERT4Rec** (standalone) with **BERT4Rec + GNN hybrids** (all fusion variants) to test whether adding GNN improves bidirectional transformers for sequential recommendation.\n",
    "\n",
    "**Key Difference from Previous Experiments:**\n",
    "- Previous hybrids used **SASRec** (unidirectional) + GNN\n",
    "- These new hybrids use **BERT4Rec** (bidirectional) + GNN\n",
    "- Bidirectional attention is more powerful ‚Üí fairer comparison\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Configuration\n",
    "\n",
    "**Training Settings:**\n",
    "- Max Epochs: 200 (with early stopping)\n",
    "- Patience: 20\n",
    "- Expected convergence: epoch 30-70\n",
    "- Batch size: 256\n",
    "- Learning rate: 0.001\n",
    "- Model: d_model=64, n_heads=2, n_blocks=2, gnn_layers=2\n",
    "\n",
    "**Models to Train (5 Total):**\n",
    "\n",
    "1. ‚úÖ **BERT4Rec** (baseline - bidirectional transformer)\n",
    "2. ‚úÖ **BERT4Rec + GNN (Fixed)** - Œ±=0.5 fusion\n",
    "3. ‚úÖ **BERT4Rec + GNN (Discrete)** - bin-based fusion\n",
    "4. ‚úÖ **BERT4Rec + GNN (Learnable)** - learned bin weights\n",
    "5. ‚úÖ **BERT4Rec + GNN (Continuous)** - neural fusion function\n",
    "\n",
    "**Time Estimate: ~6-8 hours total with GPU T4**\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Quick Start\n",
    "\n",
    "1. Enable **GPU T4** accelerator (Runtime ‚Üí Change runtime type)\n",
    "2. Enable **Internet** access\n",
    "3. Run cells sequentially\n",
    "4. Download results at the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec537465",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c167edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/faroukq1/length-adaptive.git\n",
    "\n",
    "# Change to project directory\n",
    "%cd length-adaptive\n",
    "\n",
    "# Verify structure\n",
    "!ls -lh scripts/\n",
    "\n",
    "print(\"\\n‚úÖ Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efce092",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a5dd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages quietly\n",
    "!pip install -q torch-geometric tqdm scikit-learn pandas matplotlib seaborn scipy\n",
    "\n",
    "print(\"‚úÖ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac0342f",
   "metadata": {},
   "source": [
    "## Step 3: Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c2823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!python check_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f3c0b8",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Data\n",
    "\n",
    "Downloads MovieLens-1M and preprocesses if needed (2-3 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac775095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if preprocessed data exists\n",
    "data_file = 'data/ml-1m/processed/sequences.pkl'\n",
    "graph_file = 'data/graphs/cooccurrence_graph.pkl'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîç Checking Data Files\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if os.path.exists(data_file):\n",
    "    print(f\"‚úÖ Sequential data found: {data_file}\")\n",
    "    print(f\"   Size: {os.path.getsize(data_file) / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    print(f\"‚ùå Sequential data NOT found: {data_file}\")\n",
    "\n",
    "if os.path.exists(graph_file):\n",
    "    print(f\"‚úÖ Graph data found: {graph_file}\")\n",
    "    print(f\"   Size: {os.path.getsize(graph_file) / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    print(f\"‚ùå Graph data NOT found: {graph_file}\")\n",
    "\n",
    "# Check raw data\n",
    "raw_file = 'data/ml-1m/raw/ml-1m/ratings.dat'\n",
    "if os.path.exists(raw_file):\n",
    "    print(f\"‚úÖ Raw data found: {raw_file}\")\n",
    "else:\n",
    "    print(f\"‚ùå Raw data NOT found: {raw_file}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# If data is missing, run preprocessing\n",
    "if not os.path.exists(data_file) or not os.path.exists(graph_file):\n",
    "    print(\"\\nüîß Running preprocessing...\")\n",
    "    print(\"This will take 2-3 minutes.\\n\")\n",
    "    \n",
    "    # Download MovieLens-1M if needed\n",
    "    if not os.path.exists(raw_file):\n",
    "        print(\"üì• Downloading MovieLens-1M dataset...\")\n",
    "        !mkdir -p data/ml-1m/raw\n",
    "        !wget -q http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
    "        !unzip -q ml-1m.zip\n",
    "        !mv ml-1m data/ml-1m/raw/\n",
    "        !rm -f ml-1m.zip\n",
    "        print(\"‚úÖ Download complete!\\n\")\n",
    "    \n",
    "    # Run preprocessing\n",
    "    print(\"üîÑ Preprocessing sequential data...\")\n",
    "    !python -m src.data.preprocess\n",
    "    \n",
    "    # Build graph\n",
    "    print(\"\\nüîÑ Building co-occurrence graph...\")\n",
    "    !python -m src.data.graph_builder\n",
    "    \n",
    "    print(\"\\n‚úÖ Preprocessing complete!\")\n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"\\n‚úÖ All data files ready!\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd62e10",
   "metadata": {},
   "source": [
    "## Step 5: Run BERT4Rec + GNN Hybrid Experiments\n",
    "\n",
    "**‚è±Ô∏è Time: ~6-8 hours total (GPU T4)**\n",
    "\n",
    "This will train BERT4Rec baseline + 4 hybrid variants sequentially with paper-quality settings:\n",
    "- 200 max epochs with early stopping (patience=20)\n",
    "- Models typically converge at epoch 30-70\n",
    "- Fair comparison: all models use bidirectional attention\n",
    "- Tests whether GNN improves BERT4Rec performance\n",
    "\n",
    "**Models:**\n",
    "1. BERT4Rec (baseline)\n",
    "2. BERT4Rec + GNN (Fixed fusion, Œ±=0.5)\n",
    "3. BERT4Rec + GNN (Discrete bins)\n",
    "4. BERT4Rec + GNN (Learnable bins)\n",
    "5. BERT4Rec + GNN (Continuous neural fusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run BERT hybrid experiments\n",
    "print(\"=\"*80)\n",
    "print(\"üéì BERT4Rec + GNN HYBRID EXPERIMENTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\")\n",
    "print(\"Training 5 models with 200 epochs, early stopping patience=20\")\n",
    "print(\"Expected convergence: epoch 30-70\")\n",
    "print(\"Time estimate: ~6-8 hours with GPU T4\")\n",
    "print(\"\")\n",
    "print(\"Baseline:\")\n",
    "print(\"  1. BERT4Rec (Bidirectional Transformer, CIKM 2019)\")\n",
    "print(\"\")\n",
    "print(\"Hybrid Models (Ours - BERT4Rec base):\")\n",
    "print(\"  2. BERT4Rec + GNN (Fixed fusion, Œ±=0.5)\")\n",
    "print(\"  3. BERT4Rec + GNN (Discrete bins)\")\n",
    "print(\"  4. BERT4Rec + GNN (Learnable bins)\")\n",
    "print(\"  5. BERT4Rec + GNN (Continuous neural fusion)\")\n",
    "print(\"\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run the BERT hybrid experiments script\n",
    "!bash scripts/run_bert_hybrid_experiments.sh\n",
    "\n",
    "print(\"\\n‚úÖ All BERT hybrid experiments complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9f2f6e",
   "metadata": {},
   "source": [
    "## Step 6: Generate Comparison Results\n",
    "\n",
    "Create comparison tables specifically for BERT4Rec vs BERT+GNN hybrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f1a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comparison for BERT models\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä Analyzing BERT4Rec vs BERT+GNN Hybrid Results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_dir = Path('results')\n",
    "models_to_compare = [\n",
    "    'bert4rec',\n",
    "    'bert_hybrid_fixed', \n",
    "    'bert_hybrid_discrete',\n",
    "    'bert_hybrid_learnable',\n",
    "    'bert_hybrid_continuous'\n",
    "]\n",
    "\n",
    "# Collect results\n",
    "results_data = []\n",
    "for result_folder in sorted(results_dir.glob('*')):\n",
    "    if result_folder.is_dir():\n",
    "        results_file = result_folder / 'results.json'\n",
    "        config_file = result_folder / 'config.json'\n",
    "        \n",
    "        if results_file.exists() and config_file.exists():\n",
    "            with open(results_file) as f:\n",
    "                results = json.load(f)\n",
    "            with open(config_file) as f:\n",
    "                config = json.load(f)\n",
    "            \n",
    "            model_name = config['model']\n",
    "            \n",
    "            # Only include BERT models\n",
    "            if model_name in models_to_compare:\n",
    "                results_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'HR@5': results['test_metrics']['HR@5'],\n",
    "                    'HR@10': results['test_metrics']['HR@10'],\n",
    "                    'HR@20': results['test_metrics']['HR@20'],\n",
    "                    'NDCG@5': results['test_metrics']['NDCG@5'],\n",
    "                    'NDCG@10': results['test_metrics']['NDCG@10'],\n",
    "                    'NDCG@20': results['test_metrics']['NDCG@20'],\n",
    "                    'MRR@5': results['test_metrics']['MRR@5'],\n",
    "                    'MRR@10': results['test_metrics']['MRR@10'],\n",
    "                    'MRR@20': results['test_metrics']['MRR@20'],\n",
    "                    'Best Epoch': results['best_epoch'],\n",
    "                    'Best Val NDCG@10': results['best_val_metric'],\n",
    "                    'Short HR@10': results['grouped_metrics']['short']['HR@10'],\n",
    "                    'Short NDCG@10': results['grouped_metrics']['short']['NDCG@10'],\n",
    "                    'Medium HR@10': results['grouped_metrics']['medium']['HR@10'],\n",
    "                    'Medium NDCG@10': results['grouped_metrics']['medium']['NDCG@10'],\n",
    "                })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results_data)\n",
    "\n",
    "# Sort by NDCG@10\n",
    "df = df.sort_values('NDCG@10', ascending=False)\n",
    "\n",
    "# Save overall comparison\n",
    "overall_file = 'results/bert_hybrid_comparison_overall.csv'\n",
    "df[['Model', 'HR@10', 'NDCG@10', 'MRR@10', 'Best Epoch', 'Best Val NDCG@10']].to_csv(\n",
    "    overall_file, index=False\n",
    ")\n",
    "print(f\"\\n‚úÖ Overall comparison saved: {overall_file}\")\n",
    "\n",
    "# Save short sequence comparison\n",
    "short_file = 'results/bert_hybrid_comparison_short.csv'\n",
    "df[['Model', 'Short HR@10', 'Short NDCG@10']].rename(\n",
    "    columns={'Short HR@10': 'HR@10', 'Short NDCG@10': 'NDCG@10'}\n",
    ").to_csv(short_file, index=False)\n",
    "print(f\"‚úÖ Short sequence comparison saved: {short_file}\")\n",
    "\n",
    "# Save medium sequence comparison\n",
    "medium_file = 'results/bert_hybrid_comparison_medium.csv'\n",
    "df[['Model', 'Medium HR@10', 'Medium NDCG@10']].rename(\n",
    "    columns={'Medium HR@10': 'HR@10', 'Medium NDCG@10': 'NDCG@10'}\n",
    ").to_csv(medium_file, index=False)\n",
    "print(f\"‚úÖ Medium sequence comparison saved: {medium_file}\")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìà OVERALL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(df[['Model', 'HR@10', 'NDCG@10', 'MRR@10']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä SHORT SEQUENCES (<10 items)\")\n",
    "print(\"=\"*70)\n",
    "print(df[['Model', 'Short HR@10', 'Short NDCG@10']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä MEDIUM SEQUENCES (10-50 items)\")\n",
    "print(\"=\"*70)\n",
    "print(df[['Model', 'Medium HR@10', 'Medium NDCG@10']].to_string(index=False))\n",
    "\n",
    "# Calculate improvement/degradation\n",
    "if len(df) > 0:\n",
    "    baseline_ndcg = df[df['Model'] == 'bert4rec']['NDCG@10'].values[0]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìâ PERFORMANCE GAP vs BERT4Rec Baseline\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        model = row['Model']\n",
    "        ndcg = row['NDCG@10']\n",
    "        \n",
    "        if model != 'bert4rec':\n",
    "            diff = ((ndcg - baseline_ndcg) / baseline_ndcg) * 100\n",
    "            symbol = \"üìà\" if diff > 0 else \"üìâ\"\n",
    "            print(f\"{symbol} {model:25s}: {diff:+.2f}% ({ndcg:.6f} vs {baseline_ndcg:.6f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Analysis Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70628e58",
   "metadata": {},
   "source": [
    "## Step 7: Download Results\n",
    "\n",
    "Package all results for local analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c98b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file with all BERT hybrid results\n",
    "!mkdir -p bert_hybrid_results\n",
    "\n",
    "# Copy result files\n",
    "!cp -r results/bert4rec_* bert_hybrid_results/ 2>/dev/null || true\n",
    "!cp -r results/bert_hybrid_* bert_hybrid_results/ 2>/dev/null || true\n",
    "!cp results/bert_hybrid_comparison_*.csv bert_hybrid_results/ 2>/dev/null || true\n",
    "\n",
    "# Create archive\n",
    "!zip -r bert_hybrid_results.zip bert_hybrid_results/\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üì¶ Results Package Created\")\n",
    "print(\"=\"*70)\n",
    "print(\"\")\n",
    "print(\"‚úÖ File: bert_hybrid_results.zip\")\n",
    "print(\"\")\n",
    "print(\"Contains:\")\n",
    "print(\"  - All BERT4Rec experiment folders\")\n",
    "print(\"  - All BERT4Rec+GNN hybrid experiment folders\")\n",
    "print(\"  - Comparison CSV files\")\n",
    "print(\"\")\n",
    "print(\"Download this file to your local machine for detailed analysis!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d6242",
   "metadata": {},
   "source": [
    "## üìä Expected Outcomes\n",
    "\n",
    "Based on our previous findings with SASRec+GNN hybrids:\n",
    "\n",
    "**Hypothesis 1: GNN helps BERT4Rec**\n",
    "- BERT4Rec+GNN should outperform standalone BERT4Rec\n",
    "- Graph structure provides complementary information\n",
    "\n",
    "**Hypothesis 2: GNN hurts BERT4Rec** \n",
    "- BERT4Rec+GNN underperforms standalone BERT4Rec\n",
    "- Similar to SASRec+GNN results (-26% to -31% degradation)\n",
    "- GNN fusion creates information bottleneck\n",
    "\n",
    "**Hypothesis 3: Mixed results**\n",
    "- Some fusion strategies work, others don't\n",
    "- Length-adaptive fusion shows different patterns\n",
    "\n",
    "---\n",
    "\n",
    "## üî¨ Key Questions to Answer\n",
    "\n",
    "1. **Does GNN improve BERT4Rec?** Compare BERT4Rec vs best hybrid\n",
    "2. **Which fusion works best?** Compare the 4 fusion strategies\n",
    "3. **Length-adaptive benefits?** Do hybrids help short vs medium sequences differently?\n",
    "4. **Comparison with SASRec+GNN**: Do bidirectional transformers benefit more from GNN?\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Notes\n",
    "\n",
    "- Results will be in `results/` directory\n",
    "- Each model has: config.json, history.json, results.json\n",
    "- Training time: ~1-1.5 hours per model with GPU T4\n",
    "- Models use early stopping (patience=20) to prevent overfitting\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
