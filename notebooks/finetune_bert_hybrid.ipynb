{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"629d3a32","cell_type":"markdown","source":"# Fine-Tuning BERT Hybrid Models\n# Hyperparameter Optimization for Best Performers\n\n**Models to Fine-Tune:**\n1. **bert_hybrid_fixed** - HR@10: 0.0690, NDCG@10: 0.1447\n2. **bert_hybrid_discrete** - HR@10: 0.0655, NDCG@10: 0.1414\n\n**Strategy:**\n- Grid search over key hyperparameters\n- Track all metrics (HR@10, NDCG@10, MRR)\n- Save best configurations\n- Quick experiments (30-50 epochs with early stopping)\n\n**Time Estimate:** ~4-6 hours with GPU T4","metadata":{}},{"id":"267283ee","cell_type":"markdown","source":"## Step 1: Setup and Install Dependencies","metadata":{}},{"id":"5d334666","cell_type":"code","source":"# Check if we're in Kaggle or Colab\nimport os\nimport sys\n\n# If not already in project directory, clone it\nif not os.path.exists('length-adaptive'):\n    print(\"ğŸ“¦ Cloning repository...\")\n    !git clone https://github.com/faroukq1/length-adaptive.git\n    %cd length-adaptive\nelse:\n    print(\"âœ… Repository already exists\")\n    if os.path.basename(os.getcwd()) != 'length-adaptive':\n        %cd length-adaptive\n\nprint(f\"ğŸ“‚ Current directory: {os.getcwd()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T05:45:21.868447Z","iopub.execute_input":"2026-02-23T05:45:21.868626Z","iopub.status.idle":"2026-02-23T05:45:31.247700Z","shell.execute_reply.started":"2026-02-23T05:45:21.868607Z","shell.execute_reply":"2026-02-23T05:45:31.246875Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¦ Cloning repository...\nCloning into 'length-adaptive'...\nremote: Enumerating objects: 442, done.\u001b[K\nremote: Counting objects: 100% (284/284), done.\u001b[K\nremote: Compressing objects: 100% (228/228), done.\u001b[K\nremote: Total 442 (delta 123), reused 204 (delta 54), pack-reused 158 (from 1)\u001b[K\nReceiving objects: 100% (442/442), 153.25 MiB | 22.48 MiB/s, done.\nResolving deltas: 100% (167/167), done.\n/kaggle/working/length-adaptive\nğŸ“‚ Current directory: /kaggle/working/length-adaptive\n","output_type":"stream"}],"execution_count":1},{"id":"465a8be1","cell_type":"code","source":"# Install dependencies\nprint(\"ğŸ“¥ Installing dependencies...\")\n!pip install -q torch-geometric tqdm scikit-learn pandas matplotlib seaborn\n\nprint(\"âœ… Dependencies installed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T05:45:31.249855Z","iopub.execute_input":"2026-02-23T05:45:31.250285Z","iopub.status.idle":"2026-02-23T05:45:36.809613Z","shell.execute_reply.started":"2026-02-23T05:45:31.250257Z","shell.execute_reply":"2026-02-23T05:45:36.808899Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Installing dependencies...\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hâœ… Dependencies installed!\n","output_type":"stream"}],"execution_count":2},{"id":"d2db9f2c","cell_type":"markdown","source":"## Step 2: Verify GPU and Setup","metadata":{}},{"id":"5cfeb7f9","cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nfrom pathlib import Path\nimport pickle\nimport json\nfrom tqdm import tqdm\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Check GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"=\"*70)\nprint(f\"ğŸš€ Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"ğŸ“Š GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"ğŸ’¾ Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T05:45:36.810810Z","iopub.execute_input":"2026-02-23T05:45:36.811136Z","iopub.status.idle":"2026-02-23T05:45:41.690602Z","shell.execute_reply.started":"2026-02-23T05:45:36.811102Z","shell.execute_reply":"2026-02-23T05:45:41.689965Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nğŸš€ Device: cuda\nğŸ“Š GPU: Tesla P100-PCIE-16GB\nğŸ’¾ Memory: 15.89 GB\n======================================================================\n","output_type":"stream"}],"execution_count":3},{"id":"42fedec3","cell_type":"markdown","source":"## Step 3: Load Data and Graph","metadata":{}},{"id":"943fc701","cell_type":"code","source":"# Add project to path\nsys.path.insert(0, os.getcwd())\n\nfrom src.data.dataloader import get_dataloaders\n\nprint(\"ğŸ“‚ Loading MovieLens-1M data...\")\n\n# Load data - get_dataloaders returns all three loaders plus config\ntrain_loader, val_loader, test_loader, config = get_dataloaders(\n    data_path='data/ml-1m/processed/sequences.pkl',\n    batch_size=256,\n    max_len=200,\n    num_workers=2  # Reduce workers for Kaggle/Colab\n)\n\n# Get number of items from config\nnum_items = config['num_items']\n\nprint(f\"âœ… Data loaded successfully!\")\nprint(f\"ğŸ“Š Number of items: {num_items}\")\nprint(f\"ğŸ“Š Train batches: {len(train_loader)}\")\nprint(f\"ğŸ“Š Validation batches: {len(val_loader)}\")\nprint(f\"ğŸ“Š Test batches: {len(test_loader)}\")\n\n# Load graph for GNN component\nprint(\"\\nğŸ“Š Loading co-occurrence graph...\")\nwith open('data/graphs/cooccurrence_graph.pkl', 'rb') as f:\n    graph_data = pickle.load(f)\n\nedge_index = graph_data['edge_index']\nedge_weight = graph_data['edge_weight']\nprint(f\"âœ… Graph loaded: {edge_index.shape[1]:,} edges\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T05:45:41.691545Z","iopub.execute_input":"2026-02-23T05:45:41.691976Z","iopub.status.idle":"2026-02-23T05:45:58.785550Z","shell.execute_reply.started":"2026-02-23T05:45:41.691952Z","shell.execute_reply":"2026-02-23T05:45:58.784768Z"}},"outputs":[{"name":"stdout","text":"ğŸ“‚ Loading MovieLens-1M data...\nâœ… Data loaded successfully!\nğŸ“Š Number of items: 3533\nğŸ“Š Train batches: 2177\nğŸ“Š Validation batches: 24\nğŸ“Š Test batches: 24\n\nğŸ“Š Loading co-occurrence graph...\nâœ… Graph loaded: 151,874 edges\n","output_type":"stream"}],"execution_count":4},{"id":"8c8790a6","cell_type":"markdown","source":"## Step 4: Define Fine-Tuning Configuration\n\n**Hyperparameters to Tune:**\n1. Learning rate: [0.0005, 0.001, 0.002]\n2. d_model (embedding size): [64, 128]\n3. n_heads: [2, 4]\n4. n_blocks: [2, 3]\n5. Dropout: [0.1, 0.2]\n6. For discrete: L_short, L_long values\n7. For fixed: alpha values","metadata":{}},{"id":"0d4a6eaa","cell_type":"code","source":"# Hyperparameter search space\nhyperparameter_configs = {\n    'bert_hybrid_fixed': [\n        # Original config\n        # {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.5},\n        # Vary alpha\n        # {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.3},\n        # {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.7},\n        # Vary learning rate\n        # {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.0005, 'dropout': 0.2, 'alpha': 0.5},\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.002, 'dropout': 0.2, 'alpha': 0.5},\n        # Larger model\n        {'d_model': 128, 'n_heads': 4, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.5},\n        # Deeper model\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 3, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.5},\n        # Lower dropout\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.1, 'alpha': 0.5},\n    ],\n    \n    'bert_hybrid_discrete': [\n        # Original config\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        # Vary thresholds\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 5, 'L_long': 20},\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 15, 'L_long': 40},\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 8, 'L_long': 25},\n        # Vary learning rate\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.0005, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.002, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        # Larger model\n        {'d_model': 128, 'n_heads': 4, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        # Deeper model\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 3, 'lr': 0.001, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        # Lower dropout\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.1, 'L_short': 10, 'L_long': 30},\n    ]\n}\n\nprint(\"=\"*70)\nprint(\"ğŸ”¬ Hyperparameter Search Space\")\nprint(\"=\"*70)\nprint(f\"\\nbert_hybrid_fixed: {len(hyperparameter_configs['bert_hybrid_fixed'])} configurations\")\nprint(f\"bert_hybrid_discrete: {len(hyperparameter_configs['bert_hybrid_discrete'])} configurations\")\nprint(f\"\\nTotal experiments: {sum(len(v) for v in hyperparameter_configs.values())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T05:45:58.786615Z","iopub.execute_input":"2026-02-23T05:45:58.786992Z","iopub.status.idle":"2026-02-23T05:45:58.795959Z","shell.execute_reply.started":"2026-02-23T05:45:58.786967Z","shell.execute_reply":"2026-02-23T05:45:58.795399Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ”¬ Hyperparameter Search Space\n======================================================================\n\nbert_hybrid_fixed: 4 configurations\nbert_hybrid_discrete: 9 configurations\n\nTotal experiments: 13\n","output_type":"stream"}],"execution_count":5},{"id":"cd87877e","cell_type":"markdown","source":"## Step 5: Training Functions","metadata":{}},{"id":"0047d3c8","cell_type":"code","source":"from src.models.bert4rec_hybrid import HybridBERT4RecGNN\nfrom src.train.trainer import Trainer\nfrom src.train.loss import BPRLoss\n\ndef create_model(model_type, num_items, config):\n    \"\"\"Create model with given configuration\"\"\"\n    fusion_type = model_type.replace('bert_hybrid_', '')\n    \n    # Base parameters\n    model_params = {\n        'num_items': num_items,\n        'd_model': config['d_model'],\n        'n_heads': config['n_heads'],\n        'n_blocks': config['n_blocks'],\n        'd_ff': config['d_model'] * 4,  # Standard transformer ratio\n        'max_len': 200,\n        'gnn_layers': 2,\n        'dropout': config['dropout'],\n        'fusion_type': fusion_type,\n    }\n    \n    # Add fusion-specific parameters\n    if fusion_type == 'fixed':\n        model_params['fixed_alpha'] = config['alpha']\n    elif fusion_type == 'discrete':\n        model_params['L_short'] = config['L_short']\n        model_params['L_long'] = config['L_long']\n    \n    return HybridBERT4RecGNN(**model_params)\n\ndef train_model(model_type, config, epochs=50, patience=10):\n    \"\"\"Train a single model configuration\"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(f\"ğŸš€ Training: {model_type}\")\n    print(\"=\"*70)\n    print(f\"Config: {config}\")\n    \n    # Create model\n    model = create_model(model_type, num_items, config).to(device)\n    \n    # Setup training\n    trainer = Trainer(\n        model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        test_loader=test_loader,\n        edge_index=edge_index,\n        edge_weight=edge_weight,\n        device=device,\n        lr=config['lr'],\n        patience=patience,\n        save_dir='results/finetuning/checkpoints'\n    )\n    \n    # Train\n    history = trainer.train(num_epochs=epochs, eval_every=5)\n    \n    # Get best results\n    best_epoch = history['best_epoch']\n    best_metrics = history['val_metrics'][best_epoch]\n    \n    print(f\"\\nâœ… Training Complete!\")\n    print(f\"ğŸ“Š Best Epoch: {best_epoch}\")\n    print(f\"ğŸ“ˆ HR@10: {best_metrics['hr@10']:.6f}\")\n    print(f\"ğŸ“ˆ NDCG@10: {best_metrics['ndcg@10']:.6f}\")\n    print(f\"ğŸ“ˆ MRR: {best_metrics['mrr']:.6f}\")\n    \n    return {\n        'model_type': model_type,\n        'config': config,\n        'history': history,\n        'best_metrics': best_metrics,\n        'best_epoch': best_epoch,\n        'model': model\n    }\n\nprint(\"âœ… Training functions defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T05:45:58.796851Z","iopub.execute_input":"2026-02-23T05:45:58.797480Z","iopub.status.idle":"2026-02-23T05:46:13.585054Z","shell.execute_reply.started":"2026-02-23T05:45:58.797452Z","shell.execute_reply":"2026-02-23T05:46:13.584303Z"}},"outputs":[{"name":"stdout","text":"âœ… Training functions defined!\n","output_type":"stream"}],"execution_count":6},{"id":"781e6a2e","cell_type":"markdown","source":"## Step 6: Run Fine-Tuning Experiments\n\nThis will train all configurations. Each run takes ~15-25 minutes with early stopping.","metadata":{}},{"id":"ea753aac","cell_type":"code","source":"# Store all results\nall_results = []\n\n# Create results directory\nresults_dir = Path('results/finetuning')\nresults_dir.mkdir(parents=True, exist_ok=True)\n\nprint(\"=\"*70)\nprint(\"ğŸ”¬ Starting Fine-Tuning Experiments\")\nprint(\"=\"*70)\nprint(f\"ğŸ“ Results will be saved to: {results_dir}\")\n\n# Fine-tune bert_hybrid_fixed\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ¯ BERT Hybrid Fixed Models\")\nprint(\"=\"*70)\n\nfor i, config in enumerate(hyperparameter_configs['bert_hybrid_fixed'], 1):\n    print(f\"\\nğŸ“ Configuration {i}/{len(hyperparameter_configs['bert_hybrid_fixed'])}\")\n    \n    try:\n        result = train_model('bert_hybrid_fixed', config, epochs=50, patience=10)\n        all_results.append(result)\n        \n        # Save intermediate results\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        result_file = results_dir / f'bert_hybrid_fixed_config{i}_{timestamp}.pkl'\n        with open(result_file, 'wb') as f:\n            pickle.dump(result, f)\n        \n        print(f\"ğŸ’¾ Saved to: {result_file}\")\n        \n    except Exception as e:\n        print(f\"âŒ Error in configuration {i}: {e}\")\n        continue\n\n# Fine-tune bert_hybrid_discrete\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ¯ BERT Hybrid Discrete Models\")\nprint(\"=\"*70)\n\nfor i, config in enumerate(hyperparameter_configs['bert_hybrid_discrete'], 1):\n    print(f\"\\nğŸ“ Configuration {i}/{len(hyperparameter_configs['bert_hybrid_discrete'])}\")\n    \n    try:\n        result = train_model('bert_hybrid_discrete', config, epochs=50, patience=10)\n        all_results.append(result)\n        \n        # Save intermediate results\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        result_file = results_dir / f'bert_hybrid_discrete_config{i}_{timestamp}.pkl'\n        with open(result_file, 'wb') as f:\n            pickle.dump(result, f)\n        \n        print(f\"ğŸ’¾ Saved to: {result_file}\")\n        \n    except Exception as e:\n        print(f\"âŒ Error in configuration {i}: {e}\")\n        continue\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… All Fine-Tuning Experiments Complete!\")\nprint(\"=\"*70)\nprint(f\"ğŸ“Š Total successful runs: {len(all_results)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T05:46:13.587269Z","iopub.execute_input":"2026-02-23T05:46:13.587730Z","execution_failed":"2026-02-23T15:54:42.735Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ”¬ Starting Fine-Tuning Experiments\n======================================================================\nğŸ“ Results will be saved to: results/finetuning\n\n======================================================================\nğŸ¯ BERT Hybrid Fixed Models\n======================================================================\n\nğŸ“ Configuration 1/4\n\n======================================================================\nğŸš€ Training: bert_hybrid_fixed\n======================================================================\nConfig: {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.002, 'dropout': 0.2, 'alpha': 0.5}\n============================================================\nSTARTING TRAINING\n============================================================\nDevice: cuda\nModel parameters: 569,408\nTraining batches: 2177\nValidation batches: 24\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.74it/s, loss=0.3285]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.97it/s, loss=0.2638]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.97it/s, loss=0.2288]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.98it/s, loss=0.2308]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.97it/s, loss=0.1925]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 30.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5/50] Time: 109.9s\n  Train Loss: 0.2541\n  Val HR@10: 0.0262\n  Val NDCG@10: 0.0113\n  Val MRR@10: 0.0070\n  âœ“ New best! (0.0000 â†’ 0.0113)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.99it/s, loss=0.1875]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.98it/s, loss=0.2575]\nEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.97it/s, loss=0.2765]\nEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.96it/s, loss=0.1698]\nEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.97it/s, loss=0.1885]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 109.8s\n  Train Loss: 0.2464\n  Val HR@10: 0.0318\n  Val NDCG@10: 0.0148\n  Val MRR@10: 0.0097\n  âœ“ New best! (0.0113 â†’ 0.0148)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.92it/s, loss=0.2351]\nEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.97it/s, loss=0.2593]\nEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.2028]\nEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.2062]\nEpoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1563]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15/50] Time: 109.6s\n  Train Loss: 0.2219\n  Val HR@10: 0.0370\n  Val NDCG@10: 0.0174\n  Val MRR@10: 0.0117\n  âœ“ New best! (0.0148 â†’ 0.0174)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1670]\nEpoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.2213]\nEpoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.1634]\nEpoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.2421]\nEpoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1838]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20/50] Time: 109.6s\n  Train Loss: 0.2067\n  Val HR@10: 0.0361\n  Val NDCG@10: 0.0169\n  Val MRR@10: 0.0112\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.2594]\nEpoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.2192]\nEpoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.98it/s, loss=0.2524]\nEpoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.98it/s, loss=0.2010]\nEpoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.84it/s, loss=0.2308]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25/50] Time: 110.5s\n  Train Loss: 0.2021\n  Val HR@10: 0.0424\n  Val NDCG@10: 0.0201\n  Val MRR@10: 0.0135\n  âœ“ New best! (0.0174 â†’ 0.0201)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.84it/s, loss=0.1551]\nEpoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.92it/s, loss=0.2115]\nEpoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.95it/s, loss=0.1182]\nEpoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.97it/s, loss=0.2333]\nEpoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.97it/s, loss=0.2222]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30/50] Time: 109.8s\n  Train Loss: 0.1952\n  Val HR@10: 0.0403\n  Val NDCG@10: 0.0189\n  Val MRR@10: 0.0125\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.89it/s, loss=0.1118]\nEpoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.84it/s, loss=0.2696]\nEpoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.90it/s, loss=0.2008]\nEpoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.99it/s, loss=0.2346]\nEpoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.2400]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35/50] Time: 109.6s\n  Train Loss: 0.1941\n  Val HR@10: 0.0424\n  Val NDCG@10: 0.0202\n  Val MRR@10: 0.0136\n  âœ“ New best! (0.0201 â†’ 0.0202)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1998]\nEpoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.2211]\nEpoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1559]\nEpoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.2432]\nEpoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.83it/s, loss=0.1908]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40/50] Time: 110.5s\n  Train Loss: 0.1916\n  Val HR@10: 0.0388\n  Val NDCG@10: 0.0185\n  Val MRR@10: 0.0123\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1645]\nEpoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.1580]\nEpoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.86it/s, loss=0.1396]\nEpoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.96it/s, loss=0.1740]\nEpoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.2132]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45/50] Time: 109.6s\n  Train Loss: 0.1901\n  Val HR@10: 0.0466\n  Val NDCG@10: 0.0218\n  Val MRR@10: 0.0145\n  âœ“ New best! (0.0202 â†’ 0.0218)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.97it/s, loss=0.2263]\nEpoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1800]\nEpoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.1324]\nEpoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.2353]\nEpoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1258]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50/50] Time: 109.6s\n  Train Loss: 0.1906\n  Val HR@10: 0.0394\n  Val NDCG@10: 0.0194\n  Val MRR@10: 0.0134\n  No improvement (1/10)\n\n============================================================\nTRAINING COMPLETE\n============================================================\nTotal time: 91.0 minutes\nBest epoch: 45\nBest val NDCG@10: 0.0218\n============================================================\n\nâŒ Error in configuration 1: list index out of range\n\nğŸ“ Configuration 2/4\n\n======================================================================\nğŸš€ Training: bert_hybrid_fixed\n======================================================================\nConfig: {'d_model': 128, 'n_heads': 4, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.5}\n============================================================\nSTARTING TRAINING\n============================================================\nDevice: cuda\nModel parameters: 1,343,616\nTraining batches: 2177\nValidation batches: 24\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.2570]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.1681]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.2170]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.1951]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.72it/s, loss=0.1798]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 22.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5/50] Time: 204.2s\n  Train Loss: 0.1769\n  Val HR@10: 0.0610\n  Val NDCG@10: 0.0293\n  Val MRR@10: 0.0197\n  âœ“ New best! (0.0000 â†’ 0.0293)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.72it/s, loss=0.2623]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.1338]\nEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.1607]\nEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.1842]\nEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.2025]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 22.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 204.4s\n  Train Loss: 0.1459\n  Val HR@10: 0.0729\n  Val NDCG@10: 0.0344\n  Val MRR@10: 0.0230\n  âœ“ New best! (0.0293 â†’ 0.0344)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.0950]\nEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1445]\nEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1302]\nEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.1955]\nEpoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0992]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 22.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15/50] Time: 204.5s\n  Train Loss: 0.1324\n  Val HR@10: 0.0890\n  Val NDCG@10: 0.0419\n  Val MRR@10: 0.0279\n  âœ“ New best! (0.0344 â†’ 0.0419)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1560]\nEpoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0933]\nEpoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1176]\nEpoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1645]\nEpoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1423]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 22.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20/50] Time: 204.5s\n  Train Loss: 0.1254\n  Val HR@10: 0.0970\n  Val NDCG@10: 0.0459\n  Val MRR@10: 0.0307\n  âœ“ New best! (0.0419 â†’ 0.0459)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.1716]\nEpoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0695]\nEpoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.1368]\nEpoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1115]\nEpoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0722]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 21.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25/50] Time: 204.6s\n  Train Loss: 0.1198\n  Val HR@10: 0.1021\n  Val NDCG@10: 0.0480\n  Val MRR@10: 0.0320\n  âœ“ New best! (0.0459 â†’ 0.0480)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.1242]\nEpoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.1301]\nEpoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0676]\nEpoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1209]\nEpoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0556]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 21.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30/50] Time: 204.6s\n  Train Loss: 0.1141\n  Val HR@10: 0.0999\n  Val NDCG@10: 0.0484\n  Val MRR@10: 0.0330\n  âœ“ New best! (0.0480 â†’ 0.0484)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1026]\nEpoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.0974]\nEpoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.2303]\nEpoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1078]\nEpoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1134]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 21.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35/50] Time: 204.5s\n  Train Loss: 0.1108\n  Val HR@10: 0.1018\n  Val NDCG@10: 0.0494\n  Val MRR@10: 0.0338\n  âœ“ New best! (0.0484 â†’ 0.0494)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0601]\nEpoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1809]\nEpoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.71it/s, loss=0.0889]\nEpoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0582]\nEpoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0762]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 21.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40/50] Time: 204.6s\n  Train Loss: 0.1086\n  Val HR@10: 0.1099\n  Val NDCG@10: 0.0556\n  Val MRR@10: 0.0393\n  âœ“ New best! (0.0494 â†’ 0.0556)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.0795]\nEpoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1937]\nEpoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.70it/s, loss=0.1332]\nEpoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.0585]\nEpoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.0637]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 22.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45/50] Time: 204.7s\n  Train Loss: 0.1066\n  Val HR@10: 0.1119\n  Val NDCG@10: 0.0538\n  Val MRR@10: 0.0365\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.1048]\nEpoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.1522]\nEpoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.68it/s, loss=0.1547]\nEpoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.0564]\nEpoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [03:23<00:00, 10.69it/s, loss=0.0539]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:01<00:00, 22.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50/50] Time: 204.6s\n  Train Loss: 0.1023\n  Val HR@10: 0.1069\n  Val NDCG@10: 0.0529\n  Val MRR@10: 0.0367\n  No improvement (2/10)\n\n============================================================\nTRAINING COMPLETE\n============================================================\nTotal time: 169.7 minutes\nBest epoch: 40\nBest val NDCG@10: 0.0556\n============================================================\n\nâŒ Error in configuration 2: list index out of range\n\nğŸ“ Configuration 3/4\n\n======================================================================\nğŸš€ Training: bert_hybrid_fixed\n======================================================================\nConfig: {'d_model': 64, 'n_heads': 2, 'n_blocks': 3, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.5}\n============================================================\nSTARTING TRAINING\n============================================================\nDevice: cuda\nModel parameters: 619,392\nTraining batches: 2177\nValidation batches: 24\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.1956]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.1445]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.74it/s, loss=0.1729]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.72it/s, loss=0.1485]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.76it/s, loss=0.1536]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 27.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5/50] Time: 148.4s\n  Train Loss: 0.1465\n  Val HR@10: 0.0795\n  Val NDCG@10: 0.0368\n  Val MRR@10: 0.0241\n  âœ“ New best! (0.0000 â†’ 0.0368)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.75it/s, loss=0.1024]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.1201]\nEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.1160]\nEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.1297]\nEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.2147]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 27.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 148.3s\n  Train Loss: 0.1225\n  Val HR@10: 0.0991\n  Val NDCG@10: 0.0459\n  Val MRR@10: 0.0301\n  âœ“ New best! (0.0368 â†’ 0.0459)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.0893]\nEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.0663]\nEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.1573]\nEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.78it/s, loss=0.1294]\nEpoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.76it/s, loss=0.2385]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 27.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15/50] Time: 148.3s\n  Train Loss: 0.1104\n  Val HR@10: 0.1090\n  Val NDCG@10: 0.0505\n  Val MRR@10: 0.0331\n  âœ“ New best! (0.0459 â†’ 0.0505)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.1195]\nEpoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.74it/s, loss=0.1000]\nEpoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.75it/s, loss=0.1314]\nEpoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.76it/s, loss=0.0701]\nEpoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.78it/s, loss=0.1557]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 26.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20/50] Time: 148.2s\n  Train Loss: 0.1058\n  Val HR@10: 0.1147\n  Val NDCG@10: 0.0568\n  Val MRR@10: 0.0395\n  âœ“ New best! (0.0505 â†’ 0.0568)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.0675]\nEpoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.1440]\nEpoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.77it/s, loss=0.1279]\nEpoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:27<00:00, 14.75it/s, loss=0.0853]\nEpoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.1353]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 26.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25/50] Time: 149.7s\n  Train Loss: 0.1016\n  Val HR@10: 0.1206\n  Val NDCG@10: 0.0561\n  Val MRR@10: 0.0368\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.64it/s, loss=0.0729]\nEpoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.1040]\nEpoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.64it/s, loss=0.0431]\nEpoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.64it/s, loss=0.0816]\nEpoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.64it/s, loss=0.0903]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 26.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30/50] Time: 149.6s\n  Train Loss: 0.0982\n  Val HR@10: 0.1185\n  Val NDCG@10: 0.0567\n  Val MRR@10: 0.0382\n  No improvement (2/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.0591]\nEpoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.64it/s, loss=0.1360]\nEpoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.64it/s, loss=0.1557]\nEpoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.66it/s, loss=0.0751]\nEpoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.65it/s, loss=0.1255]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 26.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35/50] Time: 149.5s\n  Train Loss: 0.0948\n  Val HR@10: 0.1291\n  Val NDCG@10: 0.0614\n  Val MRR@10: 0.0413\n  âœ“ New best! (0.0568 â†’ 0.0614)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.0488]\nEpoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.1767]\nEpoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.64it/s, loss=0.0526]\nEpoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.1890]\nEpoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.1557]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 26.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40/50] Time: 149.7s\n  Train Loss: 0.0927\n  Val HR@10: 0.1314\n  Val NDCG@10: 0.0618\n  Val MRR@10: 0.0411\n  âœ“ New best! (0.0614 â†’ 0.0618)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.0549]\nEpoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.0858]\nEpoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.1119]\nEpoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.64it/s, loss=0.1597]\nEpoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.0668]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 26.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45/50] Time: 149.7s\n  Train Loss: 0.0911\n  Val HR@10: 0.1276\n  Val NDCG@10: 0.0621\n  Val MRR@10: 0.0425\n  âœ“ New best! (0.0618 â†’ 0.0621)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.62it/s, loss=0.0911]\nEpoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.63it/s, loss=0.0688]\nEpoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.62it/s, loss=0.1066]\nEpoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.62it/s, loss=0.0573]\nEpoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [02:28<00:00, 14.62it/s, loss=0.0825]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 26.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50/50] Time: 149.8s\n  Train Loss: 0.0898\n  Val HR@10: 0.1288\n  Val NDCG@10: 0.0634\n  Val MRR@10: 0.0438\n  âœ“ New best! (0.0621 â†’ 0.0634)\n\n============================================================\nTRAINING COMPLETE\n============================================================\nTotal time: 123.6 minutes\nBest epoch: 50\nBest val NDCG@10: 0.0634\n============================================================\n\nâŒ Error in configuration 3: list index out of range\n\nğŸ“ Configuration 4/4\n\n======================================================================\nğŸš€ Training: bert_hybrid_fixed\n======================================================================\nConfig: {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.1, 'alpha': 0.5}\n============================================================\nSTARTING TRAINING\n============================================================\nDevice: cuda\nModel parameters: 569,408\nTraining batches: 2177\nValidation batches: 24\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.80it/s, loss=0.1515]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.79it/s, loss=0.1088]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.79it/s, loss=0.0887]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.83it/s, loss=0.1320]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.83it/s, loss=0.1507]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5/50] Time: 110.6s\n  Train Loss: 0.1297\n  Val HR@10: 0.0883\n  Val NDCG@10: 0.0411\n  Val MRR@10: 0.0271\n  âœ“ New best! (0.0000 â†’ 0.0411)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.82it/s, loss=0.0791]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.80it/s, loss=0.0760]\nEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.80it/s, loss=0.1476]\nEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.79it/s, loss=0.0818]\nEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.81it/s, loss=0.0818]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 110.7s\n  Train Loss: 0.1086\n  Val HR@10: 0.1122\n  Val NDCG@10: 0.0542\n  Val MRR@10: 0.0369\n  âœ“ New best! (0.0411 â†’ 0.0542)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.80it/s, loss=0.0955]\nEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.81it/s, loss=0.1689]\nEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.80it/s, loss=0.1265]\nEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.80it/s, loss=0.1079]\nEpoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.81it/s, loss=0.0864]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15/50] Time: 110.7s\n  Train Loss: 0.1005\n  Val HR@10: 0.1056\n  Val NDCG@10: 0.0502\n  Val MRR@10: 0.0337\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.82it/s, loss=0.1248]\nEpoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.84it/s, loss=0.1353]\nEpoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.84it/s, loss=0.0460]\nEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.63it/s, loss=0.1415]\nEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.68it/s, loss=0.1474]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 111.4s\n  Train Loss: 0.1172\n  Val HR@10: 0.1082\n  Val NDCG@10: 0.0510\n  Val MRR@10: 0.0339\n  âœ“ New best! (0.0426 â†’ 0.0510)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.72it/s, loss=0.1060]\nEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.72it/s, loss=0.0706]\nEpoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.70it/s, loss=0.0820]\nEpoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.72it/s, loss=0.1062]\nEpoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.69it/s, loss=0.1548]\nEpoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.69it/s, loss=0.0896]\nEpoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.72it/s, loss=0.0796]\nEpoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.72it/s, loss=0.0632]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 30.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30/50] Time: 111.2s\n  Train Loss: 0.0952\n  Val HR@10: 0.1129\n  Val NDCG@10: 0.0553\n  Val MRR@10: 0.0381\n  No improvement (2/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.69it/s, loss=0.0919]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 30.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35/50] Time: 111.3s\n  Train Loss: 0.0925\n  Val HR@10: 0.1296\n  Val NDCG@10: 0.0627\n  Val MRR@10: 0.0428\n  âœ“ New best! (0.0589 â†’ 0.0627)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.68it/s, loss=0.1754]\nEpoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.68it/s, loss=0.0628]\nEpoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.72it/s, loss=0.1166]\nEpoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.71it/s, loss=0.1069]\nEpoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.70it/s, loss=0.0858]\nEpoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.69it/s, loss=0.0656]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.78it/s, loss=0.1312]]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.78it/s, loss=0.0832]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5/50] Time: 110.8s\n  Train Loss: 0.1449\n  Val HR@10: 0.0825\n  Val NDCG@10: 0.0404\n  Val MRR@10: 0.0278\n  âœ“ New best! (0.0000 â†’ 0.0404)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.75it/s, loss=0.1182]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 111.0s\n  Train Loss: 0.1180\n  Val HR@10: 0.0902\n  Val NDCG@10: 0.0426\n  Val MRR@10: 0.0285\n  âœ“ New best! (0.0404 â†’ 0.0426)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:50<00:00, 19.77it/s, loss=0.1272]\nEpoch 12:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2023/2177 [01:42<00:07, 19.83it/s, loss=0.0970]","output_type":"stream"}],"execution_count":null},{"id":"ac144a2b","cell_type":"markdown","source":"## Step 7: Analyze Results","metadata":{}},{"id":"e1aad319","cell_type":"code","source":"# Create results DataFrame\nresults_data = []\n\nfor result in all_results:\n    row = {\n        'Model': result['model_type'],\n        'HR@10': result['best_metrics']['hr@10'],\n        'NDCG@10': result['best_metrics']['ndcg@10'],\n        'MRR': result['best_metrics']['mrr'],\n        'Best Epoch': result['best_epoch'],\n        **result['config']  # Add all config parameters\n    }\n    results_data.append(row)\n\nresults_df = pd.DataFrame(results_data)\n\n# Sort by NDCG@10\nresults_df = results_df.sort_values('NDCG@10', ascending=False)\n\nprint(\"=\"*70)\nprint(\"ğŸ“Š Fine-Tuning Results Summary\")\nprint(\"=\"*70)\nprint(results_df.to_string(index=False))\n\n# Save results\nresults_csv = results_dir / 'finetuning_results.csv'\nresults_df.to_csv(results_csv, index=False)\nprint(f\"\\nğŸ’¾ Results saved to: {results_csv}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T15:54:42.736Z"}},"outputs":[],"execution_count":null},{"id":"242cf045","cell_type":"code","source":"# Identify best configurations\nprint(\"=\"*70)\nprint(\"ğŸ† Best Configurations\")\nprint(\"=\"*70)\n\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_results = results_df[results_df['Model'] == model_type]\n    if len(model_results) > 0:\n        best_idx = model_results['NDCG@10'].idxmax()\n        best = model_results.loc[best_idx]\n        \n        print(f\"\\n{model_type}:\")\n        print(f\"  HR@10: {best['HR@10']:.6f}\")\n        print(f\"  NDCG@10: {best['NDCG@10']:.6f}\")\n        print(f\"  MRR: {best['MRR']:.6f}\")\n        print(f\"  Configuration:\")\n        for key, value in best.items():\n            if key not in ['Model', 'HR@10', 'NDCG@10', 'MRR', 'Best Epoch']:\n                print(f\"    {key}: {value}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T15:54:42.736Z"}},"outputs":[],"execution_count":null},{"id":"6bd78c0b","cell_type":"markdown","source":"## Step 8: Visualizations","metadata":{}},{"id":"34db20f5","cell_type":"code","source":"# Create visualizations\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# 1. NDCG@10 comparison\nax = axes[0, 0]\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_data = results_df[results_df['Model'] == model_type]\n    ax.scatter(range(len(model_data)), model_data['NDCG@10'], \n              label=model_type, s=100, alpha=0.7)\nax.set_xlabel('Configuration Index', fontsize=12)\nax.set_ylabel('NDCG@10', fontsize=12)\nax.set_title('NDCG@10 across Configurations', fontsize=14, fontweight='bold')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# 2. HR@10 vs NDCG@10\nax = axes[0, 1]\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_data = results_df[results_df['Model'] == model_type]\n    ax.scatter(model_data['HR@10'], model_data['NDCG@10'], \n              label=model_type, s=100, alpha=0.7)\nax.set_xlabel('HR@10', fontsize=12)\nax.set_ylabel('NDCG@10', fontsize=12)\nax.set_title('HR@10 vs NDCG@10', fontsize=14, fontweight='bold')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# 3. Learning rate effect (for fixed)\nax = axes[1, 0]\nif 'lr' in results_df.columns:\n    fixed_data = results_df[results_df['Model'] == 'bert_hybrid_fixed']\n    if len(fixed_data) > 0:\n        lr_groups = fixed_data.groupby('lr')['NDCG@10'].mean()\n        ax.bar(range(len(lr_groups)), lr_groups.values)\n        ax.set_xticks(range(len(lr_groups)))\n        ax.set_xticklabels([f'{lr:.4f}' for lr in lr_groups.index])\n        ax.set_xlabel('Learning Rate', fontsize=12)\n        ax.set_ylabel('Average NDCG@10', fontsize=12)\n        ax.set_title('Learning Rate Effect (Fixed)', fontsize=14, fontweight='bold')\n        ax.grid(True, alpha=0.3, axis='y')\n\n# 4. Model size effect\nax = axes[1, 1]\nif 'd_model' in results_df.columns:\n    size_groups = results_df.groupby('d_model')['NDCG@10'].mean()\n    ax.bar(range(len(size_groups)), size_groups.values, color='coral')\n    ax.set_xticks(range(len(size_groups)))\n    ax.set_xticklabels([f'{size}' for size in size_groups.index])\n    ax.set_xlabel('Model Size (d_model)', fontsize=12)\n    ax.set_ylabel('Average NDCG@10', fontsize=12)\n    ax.set_title('Model Size Effect', fontsize=14, fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig(results_dir / 'finetuning_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ… Visualizations created and saved!\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T15:54:42.736Z"}},"outputs":[],"execution_count":null},{"id":"369f3e67","cell_type":"markdown","source":"## Step 9: Test Best Models\n\nEvaluate the best configuration of each model on the test set.","metadata":{}},{"id":"2da50bbf","cell_type":"code","source":"from src.eval.metrics import evaluate_model\n\n# Evaluate best models on test set\nprint(\"=\"*70)\nprint(\"ğŸ¯ Testing Best Configurations\")\nprint(\"=\"*70)\n\ntest_results = []\n\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_results = results_df[results_df['Model'] == model_type]\n    if len(model_results) == 0:\n        continue\n        \n    # Get best configuration\n    best_idx = model_results['NDCG@10'].idxmax()\n    best_result = [r for r in all_results if r['model_type'] == model_type][best_idx]\n    \n    print(f\"\\n{model_type}:\")\n    print(f\"  Best config: {best_result['config']}\")\n    \n    # Evaluate on test set\n    model = best_result['model'].to(device)\n    model.eval()\n    \n    test_metrics = evaluate_model(model, test_loader, device, k=10)\n    \n    print(f\"\\n  Test Results:\")\n    print(f\"    HR@10: {test_metrics['hr@10']:.6f}\")\n    print(f\"    NDCG@10: {test_metrics['ndcg@10']:.6f}\")\n    print(f\"    MRR: {test_metrics['mrr']:.6f}\")\n    \n    test_results.append({\n        'Model': model_type,\n        'Test_HR@10': test_metrics['hr@10'],\n        'Test_NDCG@10': test_metrics['ndcg@10'],\n        'Test_MRR': test_metrics['mrr'],\n        'Config': str(best_result['config'])\n    })\n\n# Save test results\ntest_df = pd.DataFrame(test_results)\ntest_csv = results_dir / 'test_results_best_configs.csv'\ntest_df.to_csv(test_csv, index=False)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… Test evaluation complete!\")\nprint(\"=\"*70)\nprint(test_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T15:54:42.737Z"}},"outputs":[],"execution_count":null},{"id":"ea81ae6a","cell_type":"markdown","source":"## Step 10: Save Best Models","metadata":{}},{"id":"1df37111","cell_type":"code","source":"# Save best models\nmodels_dir = results_dir / 'best_models'\nmodels_dir.mkdir(exist_ok=True)\n\nprint(\"=\"*70)\nprint(\"ğŸ’¾ Saving Best Models\")\nprint(\"=\"*70)\n\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_results = results_df[results_df['Model'] == model_type]\n    if len(model_results) == 0:\n        continue\n        \n    # Get best result\n    best_idx = model_results['NDCG@10'].idxmax()\n    best_result = [r for r in all_results if r['model_type'] == model_type][best_idx]\n    \n    # Save model\n    model_path = models_dir / f'{model_type}_best.pt'\n    torch.save({\n        'model_state_dict': best_result['model'].state_dict(),\n        'config': best_result['config'],\n        'metrics': best_result['best_metrics'],\n        'epoch': best_result['best_epoch']\n    }, model_path)\n    \n    print(f\"âœ… Saved {model_type} to {model_path}\")\n    print(f\"   NDCG@10: {best_result['best_metrics']['ndcg@10']:.6f}\")\n\nprint(\"\\nğŸ’¾ All models saved successfully!\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T15:54:42.737Z"}},"outputs":[],"execution_count":null},{"id":"fe52f45c","cell_type":"markdown","source":"## Step 11: Download Results\n\nPackage all results for download.","metadata":{}},{"id":"ece36078","cell_type":"code","source":"import shutil\n\n# Create zip file\nprint(\"ğŸ“¦ Creating results package...\")\n\nzip_path = '/tmp/finetuning_results'\nshutil.make_archive(zip_path, 'zip', results_dir)\n\nprint(f\"âœ… Results packaged: {zip_path}.zip\")\nprint(\"\\nğŸ“¥ Download the file to get all results!\")\nprint(f\"\\nIncluded:\")\nprint(f\"  - Individual experiment results (pkl files)\")\nprint(f\"  - Summary CSV: finetuning_results.csv\")\nprint(f\"  - Test results: test_results_best_configs.csv\")\nprint(f\"  - Visualizations: finetuning_analysis.png\")\nprint(f\"  - Best models: best_models/*.pt\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T15:54:42.737Z"}},"outputs":[],"execution_count":null},{"id":"95a000a5","cell_type":"markdown","source":"## Summary\n\n**Fine-Tuning Complete! ğŸ‰**\n\nThis notebook has:\n1. âœ… Trained multiple configurations of bert_hybrid_fixed and bert_hybrid_discrete\n2. âœ… Tested variations in: learning rate, model size, depth, dropout, fusion parameters\n3. âœ… Identified best configurations for each model\n4. âœ… Evaluated best models on test set\n5. âœ… Saved all results and best model checkpoints\n\n**Next Steps:**\n- Review the results CSV to see all configurations\n- Check the visualizations for insights\n- Use the best models for production or further experiments\n- Consider testing on other datasets","metadata":{}}]}