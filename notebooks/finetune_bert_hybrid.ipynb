{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"629d3a32","cell_type":"markdown","source":"# Fine-Tuning BERT Hybrid Models\n# Hyperparameter Optimization for Best Performers\n\n**Models to Fine-Tune:**\n1. **bert_hybrid_fixed** - HR@10: 0.0690, NDCG@10: 0.1447\n2. **bert_hybrid_discrete** - HR@10: 0.0655, NDCG@10: 0.1414\n\n**Strategy:**\n- Grid search over key hyperparameters\n- Track all metrics (HR@10, NDCG@10, MRR)\n- Save best configurations\n- Quick experiments (30-50 epochs with early stopping)\n\n**Time Estimate:** ~4-6 hours with GPU T4","metadata":{}},{"id":"267283ee","cell_type":"markdown","source":"## Step 1: Setup and Install Dependencies","metadata":{}},{"id":"5d334666","cell_type":"code","source":"# Check if we're in Kaggle or Colab\nimport os\nimport sys\n\n# If not already in project directory, clone it\nif not os.path.exists('length-adaptive'):\n    print(\"ğŸ“¦ Cloning repository...\")\n    !git clone https://github.com/faroukq1/length-adaptive.git\n    %cd length-adaptive\nelse:\n    print(\"âœ… Repository already exists\")\n    if os.path.basename(os.getcwd()) != 'length-adaptive':\n        %cd length-adaptive\n\nprint(f\"ğŸ“‚ Current directory: {os.getcwd()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T20:40:41.704698Z","iopub.execute_input":"2026-02-22T20:40:41.704891Z","iopub.status.idle":"2026-02-22T20:40:47.553062Z","shell.execute_reply.started":"2026-02-22T20:40:41.704872Z","shell.execute_reply":"2026-02-22T20:40:47.552216Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¦ Cloning repository...\nCloning into 'length-adaptive'...\nremote: Enumerating objects: 437, done.\u001b[K\nremote: Counting objects: 100% (279/279), done.\u001b[K\nremote: Compressing objects: 100% (223/223), done.\u001b[K\nremote: Total 437 (delta 120), reused 202 (delta 54), pack-reused 158 (from 1)\u001b[K\nReceiving objects: 100% (437/437), 153.24 MiB | 40.19 MiB/s, done.\nResolving deltas: 100% (164/164), done.\n/kaggle/working/length-adaptive\nğŸ“‚ Current directory: /kaggle/working/length-adaptive\n","output_type":"stream"}],"execution_count":1},{"id":"465a8be1","cell_type":"code","source":"# Install dependencies\nprint(\"ğŸ“¥ Installing dependencies...\")\n!pip install -q torch-geometric tqdm scikit-learn pandas matplotlib seaborn\n\nprint(\"âœ… Dependencies installed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T20:40:47.555300Z","iopub.execute_input":"2026-02-22T20:40:47.555585Z","iopub.status.idle":"2026-02-22T20:40:52.875682Z","shell.execute_reply.started":"2026-02-22T20:40:47.555532Z","shell.execute_reply":"2026-02-22T20:40:52.874917Z"}},"outputs":[{"name":"stdout","text":"ğŸ“¥ Installing dependencies...\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hâœ… Dependencies installed!\n","output_type":"stream"}],"execution_count":2},{"id":"d2db9f2c","cell_type":"markdown","source":"## Step 2: Verify GPU and Setup","metadata":{}},{"id":"5cfeb7f9","cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nfrom pathlib import Path\nimport pickle\nimport json\nfrom tqdm import tqdm\n\n# Set random seeds for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Check GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"=\"*70)\nprint(f\"ğŸš€ Device: {device}\")\nif torch.cuda.is_available():\n    print(f\"ğŸ“Š GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"ğŸ’¾ Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T20:40:52.876806Z","iopub.execute_input":"2026-02-22T20:40:52.877037Z","iopub.status.idle":"2026-02-22T20:40:57.583859Z","shell.execute_reply.started":"2026-02-22T20:40:52.877012Z","shell.execute_reply":"2026-02-22T20:40:57.583080Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nğŸš€ Device: cuda\nğŸ“Š GPU: Tesla P100-PCIE-16GB\nğŸ’¾ Memory: 15.89 GB\n======================================================================\n","output_type":"stream"}],"execution_count":3},{"id":"42fedec3","cell_type":"markdown","source":"## Step 3: Load Data and Graph","metadata":{}},{"id":"943fc701","cell_type":"code","source":"# Add project to path\nsys.path.insert(0, os.getcwd())\n\nfrom src.data.dataloader import get_dataloaders\n\nprint(\"ğŸ“‚ Loading MovieLens-1M data...\")\n\n# Load data - get_dataloaders returns all three loaders plus config\ntrain_loader, val_loader, test_loader, config = get_dataloaders(\n    data_path='data/ml-1m/processed/sequences.pkl',\n    batch_size=256,\n    max_len=200,\n    num_workers=2  # Reduce workers for Kaggle/Colab\n)\n\n# Get number of items from config\nnum_items = config['num_items']\n\nprint(f\"âœ… Data loaded successfully!\")\nprint(f\"ğŸ“Š Number of items: {num_items}\")\nprint(f\"ğŸ“Š Train batches: {len(train_loader)}\")\nprint(f\"ğŸ“Š Validation batches: {len(val_loader)}\")\nprint(f\"ğŸ“Š Test batches: {len(test_loader)}\")\n\n# Load graph for GNN component\nprint(\"\\nğŸ“Š Loading co-occurrence graph...\")\nwith open('data/graphs/cooccurrence_graph.pkl', 'rb') as f:\n    graph_data = pickle.load(f)\n\nedge_index = graph_data['edge_index']\nedge_weight = graph_data['edge_weight']\nprint(f\"âœ… Graph loaded: {edge_index.shape[1]:,} edges\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T20:40:57.584845Z","iopub.execute_input":"2026-02-22T20:40:57.585301Z","iopub.status.idle":"2026-02-22T20:41:14.639460Z","shell.execute_reply.started":"2026-02-22T20:40:57.585277Z","shell.execute_reply":"2026-02-22T20:41:14.638794Z"}},"outputs":[{"name":"stdout","text":"ğŸ“‚ Loading MovieLens-1M data...\nâœ… Data loaded successfully!\nğŸ“Š Number of items: 3533\nğŸ“Š Train batches: 2177\nğŸ“Š Validation batches: 24\nğŸ“Š Test batches: 24\n\nğŸ“Š Loading co-occurrence graph...\nâœ… Graph loaded: 151,874 edges\n","output_type":"stream"}],"execution_count":4},{"id":"8c8790a6","cell_type":"markdown","source":"## Step 4: Define Fine-Tuning Configuration\n\n**Hyperparameters to Tune:**\n1. Learning rate: [0.0005, 0.001, 0.002]\n2. d_model (embedding size): [64, 128]\n3. n_heads: [2, 4]\n4. n_blocks: [2, 3]\n5. Dropout: [0.1, 0.2]\n6. For discrete: L_short, L_long values\n7. For fixed: alpha values","metadata":{}},{"id":"0d4a6eaa","cell_type":"code","source":"# Hyperparameter search space\nhyperparameter_configs = {\n    'bert_hybrid_fixed': [\n        # Original config\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.5},\n        # Vary alpha\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.3},\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.7},\n        # Vary learning rate\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.0005, 'dropout': 0.2, 'alpha': 0.5},\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.002, 'dropout': 0.2, 'alpha': 0.5},\n        # Larger model\n        {'d_model': 128, 'n_heads': 4, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.5},\n        # Deeper model\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 3, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.5},\n        # Lower dropout\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.1, 'alpha': 0.5},\n    ],\n    \n    'bert_hybrid_discrete': [\n        # Original config\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        # Vary thresholds\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 5, 'L_long': 20},\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 15, 'L_long': 40},\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 8, 'L_long': 25},\n        # Vary learning rate\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.0005, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.002, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        # Larger model\n        {'d_model': 128, 'n_heads': 4, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        # Deeper model\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 3, 'lr': 0.001, 'dropout': 0.2, 'L_short': 10, 'L_long': 30},\n        # Lower dropout\n        {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.1, 'L_short': 10, 'L_long': 30},\n    ]\n}\n\nprint(\"=\"*70)\nprint(\"ğŸ”¬ Hyperparameter Search Space\")\nprint(\"=\"*70)\nprint(f\"\\nbert_hybrid_fixed: {len(hyperparameter_configs['bert_hybrid_fixed'])} configurations\")\nprint(f\"bert_hybrid_discrete: {len(hyperparameter_configs['bert_hybrid_discrete'])} configurations\")\nprint(f\"\\nTotal experiments: {sum(len(v) for v in hyperparameter_configs.values())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T20:41:14.640417Z","iopub.execute_input":"2026-02-22T20:41:14.640756Z","iopub.status.idle":"2026-02-22T20:41:14.650479Z","shell.execute_reply.started":"2026-02-22T20:41:14.640720Z","shell.execute_reply":"2026-02-22T20:41:14.649802Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ”¬ Hyperparameter Search Space\n======================================================================\n\nbert_hybrid_fixed: 8 configurations\nbert_hybrid_discrete: 9 configurations\n\nTotal experiments: 17\n","output_type":"stream"}],"execution_count":5},{"id":"cd87877e","cell_type":"markdown","source":"## Step 5: Training Functions","metadata":{}},{"id":"0047d3c8","cell_type":"code","source":"from src.models.bert4rec_hybrid import HybridBERT4RecGNN\nfrom src.train.trainer import Trainer\nfrom src.train.loss import BPRLoss\n\ndef create_model(model_type, num_items, config):\n    \"\"\"Create model with given configuration\"\"\"\n    fusion_type = model_type.replace('bert_hybrid_', '')\n    \n    # Base parameters\n    model_params = {\n        'num_items': num_items,\n        'd_model': config['d_model'],\n        'n_heads': config['n_heads'],\n        'n_blocks': config['n_blocks'],\n        'd_ff': config['d_model'] * 4,  # Standard transformer ratio\n        'max_len': 200,\n        'gnn_layers': 2,\n        'dropout': config['dropout'],\n        'fusion_type': fusion_type,\n    }\n    \n    # Add fusion-specific parameters\n    if fusion_type == 'fixed':\n        model_params['fixed_alpha'] = config['alpha']\n    elif fusion_type == 'discrete':\n        model_params['L_short'] = config['L_short']\n        model_params['L_long'] = config['L_long']\n    \n    return HybridBERT4RecGNN(**model_params)\n\ndef train_model(model_type, config, epochs=50, patience=10):\n    \"\"\"Train a single model configuration\"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(f\"ğŸš€ Training: {model_type}\")\n    print(\"=\"*70)\n    print(f\"Config: {config}\")\n    \n    # Create model\n    model = create_model(model_type, num_items, config).to(device)\n    \n    # Setup training\n    trainer = Trainer(\n        model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        test_loader=test_loader,\n        edge_index=edge_index,\n        edge_weight=edge_weight,\n        device=device,\n        lr=config['lr'],\n        patience=patience,\n        save_dir='results/finetuning/checkpoints'\n    )\n    \n    # Train\n    history = trainer.train(num_epochs=epochs, eval_every=5)\n    \n    # Get best results\n    best_epoch = history['best_epoch']\n    best_metrics = history['val_metrics'][best_epoch]\n    \n    print(f\"\\nâœ… Training Complete!\")\n    print(f\"ğŸ“Š Best Epoch: {best_epoch}\")\n    print(f\"ğŸ“ˆ HR@10: {best_metrics['hr@10']:.6f}\")\n    print(f\"ğŸ“ˆ NDCG@10: {best_metrics['ndcg@10']:.6f}\")\n    print(f\"ğŸ“ˆ MRR: {best_metrics['mrr']:.6f}\")\n    \n    return {\n        'model_type': model_type,\n        'config': config,\n        'history': history,\n        'best_metrics': best_metrics,\n        'best_epoch': best_epoch,\n        'model': model\n    }\n\nprint(\"âœ… Training functions defined!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T20:41:14.651424Z","iopub.execute_input":"2026-02-22T20:41:14.651855Z","iopub.status.idle":"2026-02-22T20:41:29.056011Z","shell.execute_reply.started":"2026-02-22T20:41:14.651826Z","shell.execute_reply":"2026-02-22T20:41:29.055347Z"}},"outputs":[{"name":"stdout","text":"âœ… Training functions defined!\n","output_type":"stream"}],"execution_count":6},{"id":"781e6a2e","cell_type":"markdown","source":"## Step 6: Run Fine-Tuning Experiments\n\nThis will train all configurations. Each run takes ~15-25 minutes with early stopping.","metadata":{}},{"id":"ea753aac","cell_type":"code","source":"# Store all results\nall_results = []\n\n# Create results directory\nresults_dir = Path('results/finetuning')\nresults_dir.mkdir(parents=True, exist_ok=True)\n\nprint(\"=\"*70)\nprint(\"ğŸ”¬ Starting Fine-Tuning Experiments\")\nprint(\"=\"*70)\nprint(f\"ğŸ“ Results will be saved to: {results_dir}\")\n\n# Fine-tune bert_hybrid_fixed\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ¯ BERT Hybrid Fixed Models\")\nprint(\"=\"*70)\n\nfor i, config in enumerate(hyperparameter_configs['bert_hybrid_fixed'], 1):\n    print(f\"\\nğŸ“ Configuration {i}/{len(hyperparameter_configs['bert_hybrid_fixed'])}\")\n    \n    try:\n        result = train_model('bert_hybrid_fixed', config, epochs=50, patience=10)\n        all_results.append(result)\n        \n        # Save intermediate results\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        result_file = results_dir / f'bert_hybrid_fixed_config{i}_{timestamp}.pkl'\n        with open(result_file, 'wb') as f:\n            pickle.dump(result, f)\n        \n        print(f\"ğŸ’¾ Saved to: {result_file}\")\n        \n    except Exception as e:\n        print(f\"âŒ Error in configuration {i}: {e}\")\n        continue\n\n# Fine-tune bert_hybrid_discrete\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ¯ BERT Hybrid Discrete Models\")\nprint(\"=\"*70)\n\nfor i, config in enumerate(hyperparameter_configs['bert_hybrid_discrete'], 1):\n    print(f\"\\nğŸ“ Configuration {i}/{len(hyperparameter_configs['bert_hybrid_discrete'])}\")\n    \n    try:\n        result = train_model('bert_hybrid_discrete', config, epochs=50, patience=10)\n        all_results.append(result)\n        \n        # Save intermediate results\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        result_file = results_dir / f'bert_hybrid_discrete_config{i}_{timestamp}.pkl'\n        with open(result_file, 'wb') as f:\n            pickle.dump(result, f)\n        \n        print(f\"ğŸ’¾ Saved to: {result_file}\")\n        \n    except Exception as e:\n        print(f\"âŒ Error in configuration {i}: {e}\")\n        continue\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… All Fine-Tuning Experiments Complete!\")\nprint(\"=\"*70)\nprint(f\"ğŸ“Š Total successful runs: {len(all_results)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T20:41:29.057905Z","iopub.execute_input":"2026-02-22T20:41:29.058312Z","execution_failed":"2026-02-23T05:31:22.487Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ”¬ Starting Fine-Tuning Experiments\n======================================================================\nğŸ“ Results will be saved to: results/finetuning\n\n======================================================================\nğŸ¯ BERT Hybrid Fixed Models\n======================================================================\n\nğŸ“ Configuration 1/8\n\n======================================================================\nğŸš€ Training: bert_hybrid_fixed\n======================================================================\nConfig: {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.5}\n============================================================\nSTARTING TRAINING\n============================================================\nDevice: cuda\nModel parameters: 569,408\nTraining batches: 2177\nValidation batches: 24\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.83it/s, loss=0.2066]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1998]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1210]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.1488]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.1356]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5/50] Time: 109.5s\n  Train Loss: 0.1386\n  Val HR@10: 0.0875\n  Val NDCG@10: 0.0416\n  Val MRR@10: 0.0279\n  âœ“ New best! (0.0000 â†’ 0.0416)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1072]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1144]\nEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.1172]\nEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.0886]\nEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.96it/s, loss=0.0683]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 109.8s\n  Train Loss: 0.1159\n  Val HR@10: 0.0968\n  Val NDCG@10: 0.0460\n  Val MRR@10: 0.0309\n  âœ“ New best! (0.0416 â†’ 0.0460)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.1188]\nEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.1098]\nEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.0912]\nEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.0768]\nEpoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.02it/s, loss=0.0716]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15/50] Time: 109.5s\n  Train Loss: 0.1080\n  Val HR@10: 0.1077\n  Val NDCG@10: 0.0506\n  Val MRR@10: 0.0337\n  âœ“ New best! (0.0460 â†’ 0.0506)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.02it/s, loss=0.0926]\nEpoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.0919]\nEpoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.0716]\nEpoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.0902]\nEpoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1407]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20/50] Time: 109.3s\n  Train Loss: 0.1023\n  Val HR@10: 0.1134\n  Val NDCG@10: 0.0547\n  Val MRR@10: 0.0372\n  âœ“ New best! (0.0506 â†’ 0.0547)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.1063]\nEpoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.0954]\nEpoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.1095]\nEpoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.1348]\nEpoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.0982]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25/50] Time: 109.2s\n  Train Loss: 0.0994\n  Val HR@10: 0.1125\n  Val NDCG@10: 0.0546\n  Val MRR@10: 0.0372\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.0822]\nEpoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.0885]\nEpoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.99it/s, loss=0.0302]\nEpoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.99it/s, loss=0.1250]\nEpoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1214]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30/50] Time: 109.6s\n  Train Loss: 0.0960\n  Val HR@10: 0.1306\n  Val NDCG@10: 0.0587\n  Val MRR@10: 0.0373\n  âœ“ New best! (0.0547 â†’ 0.0587)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.0655]\nEpoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.87it/s, loss=0.1114]\nEpoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1006]\nEpoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1105]\nEpoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1329]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35/50] Time: 109.3s\n  Train Loss: 0.0930\n  Val HR@10: 0.1321\n  Val NDCG@10: 0.0610\n  Val MRR@10: 0.0398\n  âœ“ New best! (0.0587 â†’ 0.0610)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.1642]\nEpoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.0994]\nEpoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1300]\nEpoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1005]\nEpoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.02it/s, loss=0.1091]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40/50] Time: 109.5s\n  Train Loss: 0.0909\n  Val HR@10: 0.1283\n  Val NDCG@10: 0.0600\n  Val MRR@10: 0.0396\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.0897]\nEpoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.0897]\nEpoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.02it/s, loss=0.0461]\nEpoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.0994]\nEpoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.1226]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45/50] Time: 109.5s\n  Train Loss: 0.0890\n  Val HR@10: 0.1265\n  Val NDCG@10: 0.0599\n  Val MRR@10: 0.0401\n  No improvement (2/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.1430]\nEpoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.02it/s, loss=0.0786]\nEpoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.0631]\nEpoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.0937]\nEpoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.0907]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50/50] Time: 109.4s\n  Train Loss: 0.0882\n  Val HR@10: 0.1407\n  Val NDCG@10: 0.0668\n  Val MRR@10: 0.0447\n  âœ“ New best! (0.0610 â†’ 0.0668)\n\n============================================================\nTRAINING COMPLETE\n============================================================\nTotal time: 90.7 minutes\nBest epoch: 50\nBest val NDCG@10: 0.0668\n============================================================\n\nâŒ Error in configuration 1: list index out of range\n\nğŸ“ Configuration 2/8\n\n======================================================================\nğŸš€ Training: bert_hybrid_fixed\n======================================================================\nConfig: {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.3}\n============================================================\nSTARTING TRAINING\n============================================================\nDevice: cuda\nModel parameters: 569,408\nTraining batches: 2177\nValidation batches: 24\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.2293]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1600]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1670]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.1021]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1681]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5/50] Time: 109.3s\n  Train Loss: 0.1393\n  Val HR@10: 0.0885\n  Val NDCG@10: 0.0417\n  Val MRR@10: 0.0277\n  âœ“ New best! (0.0000 â†’ 0.0417)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.1085]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1484]\nEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.0898]\nEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1324]\nEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.0630]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 109.3s\n  Train Loss: 0.1175\n  Val HR@10: 0.1139\n  Val NDCG@10: 0.0540\n  Val MRR@10: 0.0361\n  âœ“ New best! (0.0417 â†’ 0.0540)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.0865]\nEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1196]\nEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1195]\nEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1266]\nEpoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.0836]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15/50] Time: 109.4s\n  Train Loss: 0.1087\n  Val HR@10: 0.1173\n  Val NDCG@10: 0.0536\n  Val MRR@10: 0.0346\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.0490]\nEpoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.0911]\nEpoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.1221]\nEpoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1153]\nEpoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.0564]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20/50] Time: 109.4s\n  Train Loss: 0.1035\n  Val HR@10: 0.1258\n  Val NDCG@10: 0.0603\n  Val MRR@10: 0.0407\n  âœ“ New best! (0.0540 â†’ 0.0603)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.1072]\nEpoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.93it/s, loss=0.0465]\nEpoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.01it/s, loss=0.1388]\nEpoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.0875]\nEpoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.1136]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25/50] Time: 109.4s\n  Train Loss: 0.0990\n  Val HR@10: 0.1183\n  Val NDCG@10: 0.0564\n  Val MRR@10: 0.0379\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.0587]\nEpoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.1111]\nEpoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.1305]\nEpoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.0731]\nEpoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.0644]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30/50] Time: 109.6s\n  Train Loss: 0.0967\n  Val HR@10: 0.1228\n  Val NDCG@10: 0.0587\n  Val MRR@10: 0.0396\n  No improvement (2/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.0642]\nEpoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.0991]\nEpoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.1089]\nEpoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.09it/s, loss=0.0896]\nEpoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.09it/s, loss=0.0701]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35/50] Time: 109.1s\n  Train Loss: 0.0941\n  Val HR@10: 0.1382\n  Val NDCG@10: 0.0649\n  Val MRR@10: 0.0430\n  âœ“ New best! (0.0603 â†’ 0.0649)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.09it/s, loss=0.0924]\nEpoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.09it/s, loss=0.0417]\nEpoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.10it/s, loss=0.0845]\nEpoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.08it/s, loss=0.1170]\nEpoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.94it/s, loss=0.1858]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40/50] Time: 109.9s\n  Train Loss: 0.0918\n  Val HR@10: 0.1306\n  Val NDCG@10: 0.0609\n  Val MRR@10: 0.0401\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.93it/s, loss=0.0714]\nEpoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.93it/s, loss=0.0975]\nEpoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.93it/s, loss=0.0748]\nEpoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.08it/s, loss=0.1638]\nEpoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.08it/s, loss=0.0728]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45/50] Time: 109.2s\n  Train Loss: 0.0906\n  Val HR@10: 0.1291\n  Val NDCG@10: 0.0631\n  Val MRR@10: 0.0433\n  No improvement (2/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.08it/s, loss=0.0991]\nEpoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.09it/s, loss=0.0981]\nEpoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.14it/s, loss=0.0682]\nEpoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.14it/s, loss=0.0981]\nEpoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.10it/s, loss=0.0972]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50/50] Time: 109.0s\n  Train Loss: 0.0895\n  Val HR@10: 0.1410\n  Val NDCG@10: 0.0691\n  Val MRR@10: 0.0474\n  âœ“ New best! (0.0649 â†’ 0.0691)\n\n============================================================\nTRAINING COMPLETE\n============================================================\nTotal time: 90.6 minutes\nBest epoch: 50\nBest val NDCG@10: 0.0691\n============================================================\n\nâŒ Error in configuration 2: list index out of range\n\nğŸ“ Configuration 3/8\n\n======================================================================\nğŸš€ Training: bert_hybrid_fixed\n======================================================================\nConfig: {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.001, 'dropout': 0.2, 'alpha': 0.7}\n============================================================\nSTARTING TRAINING\n============================================================\nDevice: cuda\nModel parameters: 569,408\nTraining batches: 2177\nValidation batches: 24\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.2556]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.19it/s, loss=0.0999]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.1632]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1093]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.16it/s, loss=0.1084]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5/50] Time: 108.7s\n  Train Loss: 0.1403\n  Val HR@10: 0.0840\n  Val NDCG@10: 0.0396\n  Val MRR@10: 0.0264\n  âœ“ New best! (0.0000 â†’ 0.0396)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.96it/s, loss=0.0900]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.16it/s, loss=0.0885]\nEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1525]\nEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1559]\nEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.16it/s, loss=0.0967]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 108.7s\n  Train Loss: 0.1158\n  Val HR@10: 0.1036\n  Val NDCG@10: 0.0495\n  Val MRR@10: 0.0334\n  âœ“ New best! (0.0396 â†’ 0.0495)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1961]\nEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1051]\nEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.0832]\nEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.0966]\nEpoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1166]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15/50] Time: 108.7s\n  Train Loss: 0.1061\n  Val HR@10: 0.1079\n  Val NDCG@10: 0.0520\n  Val MRR@10: 0.0353\n  âœ“ New best! (0.0495 â†’ 0.0520)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1484]\nEpoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1049]\nEpoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.18it/s, loss=0.1061]\nEpoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.0579]\nEpoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.0488]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20/50] Time: 108.7s\n  Train Loss: 0.1005\n  Val HR@10: 0.1094\n  Val NDCG@10: 0.0513\n  Val MRR@10: 0.0340\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1660]\nEpoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1312]\nEpoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.09it/s, loss=0.1336]\nEpoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1553]\nEpoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.0482]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25/50] Time: 108.5s\n  Train Loss: 0.0961\n  Val HR@10: 0.1226\n  Val NDCG@10: 0.0594\n  Val MRR@10: 0.0404\n  âœ“ New best! (0.0520 â†’ 0.0594)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.0966]\nEpoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1707]\nEpoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.0544]\nEpoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1051]\nEpoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1026]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30/50] Time: 108.5s\n  Train Loss: 0.0931\n  Val HR@10: 0.1241\n  Val NDCG@10: 0.0611\n  Val MRR@10: 0.0422\n  âœ“ New best! (0.0594 â†’ 0.0611)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.19it/s, loss=0.1230]\nEpoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.22it/s, loss=0.1106]\nEpoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1255]\nEpoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.22it/s, loss=0.0393]\nEpoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.22it/s, loss=0.0918]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 30.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35/50] Time: 108.5s\n  Train Loss: 0.0910\n  Val HR@10: 0.1241\n  Val NDCG@10: 0.0569\n  Val MRR@10: 0.0369\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.22it/s, loss=0.1265]\nEpoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.22it/s, loss=0.0815]\nEpoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.22it/s, loss=0.1142]\nEpoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.0568]\nEpoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.19it/s, loss=0.1626]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40/50] Time: 108.6s\n  Train Loss: 0.0889\n  Val HR@10: 0.1318\n  Val NDCG@10: 0.0617\n  Val MRR@10: 0.0408\n  âœ“ New best! (0.0611 â†’ 0.0617)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.16it/s, loss=0.1475]\nEpoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.18it/s, loss=0.0711]\nEpoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.0756]\nEpoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.0889]\nEpoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.0790]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45/50] Time: 108.5s\n  Train Loss: 0.0870\n  Val HR@10: 0.1243\n  Val NDCG@10: 0.0584\n  Val MRR@10: 0.0388\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.14it/s, loss=0.0892]\nEpoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.16it/s, loss=0.0906]\nEpoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:49<00:00, 19.95it/s, loss=0.0813]\nEpoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.08it/s, loss=0.1438]\nEpoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.00it/s, loss=0.1176]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50/50] Time: 109.6s\n  Train Loss: 0.0846\n  Val HR@10: 0.1284\n  Val NDCG@10: 0.0609\n  Val MRR@10: 0.0408\n  No improvement (2/10)\n\n============================================================\nTRAINING COMPLETE\n============================================================\nTotal time: 90.1 minutes\nBest epoch: 40\nBest val NDCG@10: 0.0617\n============================================================\n\nâŒ Error in configuration 3: list index out of range\n\nğŸ“ Configuration 4/8\n\n======================================================================\nğŸš€ Training: bert_hybrid_fixed\n======================================================================\nConfig: {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.0005, 'dropout': 0.2, 'alpha': 0.5}\n============================================================\nSTARTING TRAINING\n============================================================\nDevice: cuda\nModel parameters: 569,408\nTraining batches: 2177\nValidation batches: 24\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.14it/s, loss=0.2025]\nEpoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.15it/s, loss=0.1436]\nEpoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1308]\nEpoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.16it/s, loss=0.1336]\nEpoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.16it/s, loss=0.1278]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 5/50] Time: 108.7s\n  Train Loss: 0.1431\n  Val HR@10: 0.0799\n  Val NDCG@10: 0.0369\n  Val MRR@10: 0.0241\n  âœ“ New best! (0.0000 â†’ 0.0369)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.0860]\nEpoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.19it/s, loss=0.0920]\nEpoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.1436]\nEpoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.17it/s, loss=0.1412]\nEpoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.0780]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 10/50] Time: 108.5s\n  Train Loss: 0.1174\n  Val HR@10: 0.1028\n  Val NDCG@10: 0.0505\n  Val MRR@10: 0.0349\n  âœ“ New best! (0.0369 â†’ 0.0505)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.18it/s, loss=0.1344]\nEpoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.19it/s, loss=0.0715]\nEpoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1049]\nEpoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.19it/s, loss=0.1384]\nEpoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1056]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 15/50] Time: 108.4s\n  Train Loss: 0.1067\n  Val HR@10: 0.1157\n  Val NDCG@10: 0.0544\n  Val MRR@10: 0.0361\n  âœ“ New best! (0.0505 â†’ 0.0544)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.0616]\nEpoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.0952]\nEpoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1896]\nEpoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.1426]\nEpoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1021]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 20/50] Time: 108.5s\n  Train Loss: 0.1000\n  Val HR@10: 0.1231\n  Val NDCG@10: 0.0589\n  Val MRR@10: 0.0397\n  âœ“ New best! (0.0544 â†’ 0.0589)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.18it/s, loss=0.1445]\nEpoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.0774]\nEpoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.0914]\nEpoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1229]\nEpoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.1273]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 25/50] Time: 108.5s\n  Train Loss: 0.0953\n  Val HR@10: 0.1260\n  Val NDCG@10: 0.0602\n  Val MRR@10: 0.0406\n  âœ“ New best! (0.0589 â†’ 0.0602)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.1198]\nEpoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.1291]\nEpoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.04it/s, loss=0.0914]\nEpoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.0964]\nEpoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.0804]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 30/50] Time: 109.2s\n  Train Loss: 0.0917\n  Val HR@10: 0.1304\n  Val NDCG@10: 0.0615\n  Val MRR@10: 0.0410\n  âœ“ New best! (0.0602 â†’ 0.0615)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.08it/s, loss=0.0730]\nEpoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.08it/s, loss=0.0918]\nEpoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.08it/s, loss=0.1405]\nEpoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.07it/s, loss=0.1605]\nEpoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.16it/s, loss=0.0931]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 35/50] Time: 108.7s\n  Train Loss: 0.0888\n  Val HR@10: 0.1400\n  Val NDCG@10: 0.0663\n  Val MRR@10: 0.0443\n  âœ“ New best! (0.0615 â†’ 0.0663)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.19it/s, loss=0.2041]\nEpoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.0564]\nEpoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1586]\nEpoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.0965]\nEpoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.21it/s, loss=0.1263]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 40/50] Time: 108.5s\n  Train Loss: 0.0864\n  Val HR@10: 0.1241\n  Val NDCG@10: 0.0607\n  Val MRR@10: 0.0417\n  No improvement (1/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.0401]\nEpoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.0899]\nEpoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 19.98it/s, loss=0.1106]\nEpoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.0789]\nEpoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.03it/s, loss=0.0845]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 31.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 45/50] Time: 109.5s\n  Train Loss: 0.0848\n  Val HR@10: 0.1314\n  Val NDCG@10: 0.0623\n  Val MRR@10: 0.0415\n  No improvement (2/10)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.0640]\nEpoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.1154]\nEpoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.05it/s, loss=0.0430]\nEpoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.06it/s, loss=0.1358]\nEpoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:47<00:00, 20.20it/s, loss=0.1133]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50] Evaluating...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 32.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n[Epoch 50/50] Time: 108.5s\n  Train Loss: 0.0826\n  Val HR@10: 0.1458\n  Val NDCG@10: 0.0676\n  Val MRR@10: 0.0445\n  âœ“ New best! (0.0663 â†’ 0.0676)\n\n============================================================\nTRAINING COMPLETE\n============================================================\nTotal time: 90.2 minutes\nBest epoch: 50\nBest val NDCG@10: 0.0676\n============================================================\n\nâŒ Error in configuration 4: list index out of range\n\nğŸ“ Configuration 5/8\n\n======================================================================\nğŸš€ Training: bert_hybrid_fixed\n======================================================================\nConfig: {'d_model': 64, 'n_heads': 2, 'n_blocks': 2, 'lr': 0.002, 'dropout': 0.2, 'alpha': 0.5}\n============================================================\nSTARTING TRAINING\n============================================================\nDevice: cuda\nModel parameters: 569,408\nTraining batches: 2177\nValidation batches: 24\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2177/2177 [01:48<00:00, 20.16it/s, loss=0.3215]\nEpoch 2:  28%|â–ˆâ–ˆâ–Š       | 610/2177 [00:30<01:17, 20.22it/s, loss=0.2591]","output_type":"stream"}],"execution_count":null},{"id":"ac144a2b","cell_type":"markdown","source":"## Step 7: Analyze Results","metadata":{}},{"id":"e1aad319","cell_type":"code","source":"# Create results DataFrame\nresults_data = []\n\nfor result in all_results:\n    row = {\n        'Model': result['model_type'],\n        'HR@10': result['best_metrics']['hr@10'],\n        'NDCG@10': result['best_metrics']['ndcg@10'],\n        'MRR': result['best_metrics']['mrr'],\n        'Best Epoch': result['best_epoch'],\n        **result['config']  # Add all config parameters\n    }\n    results_data.append(row)\n\nresults_df = pd.DataFrame(results_data)\n\n# Sort by NDCG@10\nresults_df = results_df.sort_values('NDCG@10', ascending=False)\n\nprint(\"=\"*70)\nprint(\"ğŸ“Š Fine-Tuning Results Summary\")\nprint(\"=\"*70)\nprint(results_df.to_string(index=False))\n\n# Save results\nresults_csv = results_dir / 'finetuning_results.csv'\nresults_df.to_csv(results_csv, index=False)\nprint(f\"\\nğŸ’¾ Results saved to: {results_csv}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T05:31:22.488Z"}},"outputs":[],"execution_count":null},{"id":"242cf045","cell_type":"code","source":"# Identify best configurations\nprint(\"=\"*70)\nprint(\"ğŸ† Best Configurations\")\nprint(\"=\"*70)\n\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_results = results_df[results_df['Model'] == model_type]\n    if len(model_results) > 0:\n        best_idx = model_results['NDCG@10'].idxmax()\n        best = model_results.loc[best_idx]\n        \n        print(f\"\\n{model_type}:\")\n        print(f\"  HR@10: {best['HR@10']:.6f}\")\n        print(f\"  NDCG@10: {best['NDCG@10']:.6f}\")\n        print(f\"  MRR: {best['MRR']:.6f}\")\n        print(f\"  Configuration:\")\n        for key, value in best.items():\n            if key not in ['Model', 'HR@10', 'NDCG@10', 'MRR', 'Best Epoch']:\n                print(f\"    {key}: {value}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T05:31:22.488Z"}},"outputs":[],"execution_count":null},{"id":"6bd78c0b","cell_type":"markdown","source":"## Step 8: Visualizations","metadata":{}},{"id":"34db20f5","cell_type":"code","source":"# Create visualizations\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# 1. NDCG@10 comparison\nax = axes[0, 0]\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_data = results_df[results_df['Model'] == model_type]\n    ax.scatter(range(len(model_data)), model_data['NDCG@10'], \n              label=model_type, s=100, alpha=0.7)\nax.set_xlabel('Configuration Index', fontsize=12)\nax.set_ylabel('NDCG@10', fontsize=12)\nax.set_title('NDCG@10 across Configurations', fontsize=14, fontweight='bold')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# 2. HR@10 vs NDCG@10\nax = axes[0, 1]\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_data = results_df[results_df['Model'] == model_type]\n    ax.scatter(model_data['HR@10'], model_data['NDCG@10'], \n              label=model_type, s=100, alpha=0.7)\nax.set_xlabel('HR@10', fontsize=12)\nax.set_ylabel('NDCG@10', fontsize=12)\nax.set_title('HR@10 vs NDCG@10', fontsize=14, fontweight='bold')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# 3. Learning rate effect (for fixed)\nax = axes[1, 0]\nif 'lr' in results_df.columns:\n    fixed_data = results_df[results_df['Model'] == 'bert_hybrid_fixed']\n    if len(fixed_data) > 0:\n        lr_groups = fixed_data.groupby('lr')['NDCG@10'].mean()\n        ax.bar(range(len(lr_groups)), lr_groups.values)\n        ax.set_xticks(range(len(lr_groups)))\n        ax.set_xticklabels([f'{lr:.4f}' for lr in lr_groups.index])\n        ax.set_xlabel('Learning Rate', fontsize=12)\n        ax.set_ylabel('Average NDCG@10', fontsize=12)\n        ax.set_title('Learning Rate Effect (Fixed)', fontsize=14, fontweight='bold')\n        ax.grid(True, alpha=0.3, axis='y')\n\n# 4. Model size effect\nax = axes[1, 1]\nif 'd_model' in results_df.columns:\n    size_groups = results_df.groupby('d_model')['NDCG@10'].mean()\n    ax.bar(range(len(size_groups)), size_groups.values, color='coral')\n    ax.set_xticks(range(len(size_groups)))\n    ax.set_xticklabels([f'{size}' for size in size_groups.index])\n    ax.set_xlabel('Model Size (d_model)', fontsize=12)\n    ax.set_ylabel('Average NDCG@10', fontsize=12)\n    ax.set_title('Model Size Effect', fontsize=14, fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n\nplt.tight_layout()\nplt.savefig(results_dir / 'finetuning_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"âœ… Visualizations created and saved!\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T05:31:22.488Z"}},"outputs":[],"execution_count":null},{"id":"369f3e67","cell_type":"markdown","source":"## Step 9: Test Best Models\n\nEvaluate the best configuration of each model on the test set.","metadata":{}},{"id":"2da50bbf","cell_type":"code","source":"from src.eval.metrics import evaluate_model\n\n# Evaluate best models on test set\nprint(\"=\"*70)\nprint(\"ğŸ¯ Testing Best Configurations\")\nprint(\"=\"*70)\n\ntest_results = []\n\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_results = results_df[results_df['Model'] == model_type]\n    if len(model_results) == 0:\n        continue\n        \n    # Get best configuration\n    best_idx = model_results['NDCG@10'].idxmax()\n    best_result = [r for r in all_results if r['model_type'] == model_type][best_idx]\n    \n    print(f\"\\n{model_type}:\")\n    print(f\"  Best config: {best_result['config']}\")\n    \n    # Evaluate on test set\n    model = best_result['model'].to(device)\n    model.eval()\n    \n    test_metrics = evaluate_model(model, test_loader, device, k=10)\n    \n    print(f\"\\n  Test Results:\")\n    print(f\"    HR@10: {test_metrics['hr@10']:.6f}\")\n    print(f\"    NDCG@10: {test_metrics['ndcg@10']:.6f}\")\n    print(f\"    MRR: {test_metrics['mrr']:.6f}\")\n    \n    test_results.append({\n        'Model': model_type,\n        'Test_HR@10': test_metrics['hr@10'],\n        'Test_NDCG@10': test_metrics['ndcg@10'],\n        'Test_MRR': test_metrics['mrr'],\n        'Config': str(best_result['config'])\n    })\n\n# Save test results\ntest_df = pd.DataFrame(test_results)\ntest_csv = results_dir / 'test_results_best_configs.csv'\ntest_df.to_csv(test_csv, index=False)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"âœ… Test evaluation complete!\")\nprint(\"=\"*70)\nprint(test_df.to_string(index=False))","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T05:31:22.488Z"}},"outputs":[],"execution_count":null},{"id":"ea81ae6a","cell_type":"markdown","source":"## Step 10: Save Best Models","metadata":{}},{"id":"1df37111","cell_type":"code","source":"# Save best models\nmodels_dir = results_dir / 'best_models'\nmodels_dir.mkdir(exist_ok=True)\n\nprint(\"=\"*70)\nprint(\"ğŸ’¾ Saving Best Models\")\nprint(\"=\"*70)\n\nfor model_type in ['bert_hybrid_fixed', 'bert_hybrid_discrete']:\n    model_results = results_df[results_df['Model'] == model_type]\n    if len(model_results) == 0:\n        continue\n        \n    # Get best result\n    best_idx = model_results['NDCG@10'].idxmax()\n    best_result = [r for r in all_results if r['model_type'] == model_type][best_idx]\n    \n    # Save model\n    model_path = models_dir / f'{model_type}_best.pt'\n    torch.save({\n        'model_state_dict': best_result['model'].state_dict(),\n        'config': best_result['config'],\n        'metrics': best_result['best_metrics'],\n        'epoch': best_result['best_epoch']\n    }, model_path)\n    \n    print(f\"âœ… Saved {model_type} to {model_path}\")\n    print(f\"   NDCG@10: {best_result['best_metrics']['ndcg@10']:.6f}\")\n\nprint(\"\\nğŸ’¾ All models saved successfully!\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T05:31:22.489Z"}},"outputs":[],"execution_count":null},{"id":"fe52f45c","cell_type":"markdown","source":"## Step 11: Download Results\n\nPackage all results for download.","metadata":{}},{"id":"ece36078","cell_type":"code","source":"import shutil\n\n# Create zip file\nprint(\"ğŸ“¦ Creating results package...\")\n\nzip_path = '/tmp/finetuning_results'\nshutil.make_archive(zip_path, 'zip', results_dir)\n\nprint(f\"âœ… Results packaged: {zip_path}.zip\")\nprint(\"\\nğŸ“¥ Download the file to get all results!\")\nprint(f\"\\nIncluded:\")\nprint(f\"  - Individual experiment results (pkl files)\")\nprint(f\"  - Summary CSV: finetuning_results.csv\")\nprint(f\"  - Test results: test_results_best_configs.csv\")\nprint(f\"  - Visualizations: finetuning_analysis.png\")\nprint(f\"  - Best models: best_models/*.pt\")","metadata":{"trusted":true,"execution":{"execution_failed":"2026-02-23T05:31:22.489Z"}},"outputs":[],"execution_count":null},{"id":"95a000a5","cell_type":"markdown","source":"## Summary\n\n**Fine-Tuning Complete! ğŸ‰**\n\nThis notebook has:\n1. âœ… Trained multiple configurations of bert_hybrid_fixed and bert_hybrid_discrete\n2. âœ… Tested variations in: learning rate, model size, depth, dropout, fusion parameters\n3. âœ… Identified best configurations for each model\n4. âœ… Evaluated best models on test set\n5. âœ… Saved all results and best model checkpoints\n\n**Next Steps:**\n- Review the results CSV to see all configurations\n- Check the visualizations for insights\n- Use the best models for production or further experiments\n- Consider testing on other datasets","metadata":{}}]}