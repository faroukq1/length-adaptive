{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"9f50bbeb","cell_type":"markdown","source":"# Best Models Training - BERT Hybrid + TCN + TGT\n## Publication-Quality Experiments on MovieLens-1M\n\n**Models to Train (4 Total):**\n\n1. **BERT Hybrid Fixed** (Î±=0.5)\n   - BERT4Rec + LightGCN with fixed fusion weight\n\n2. **BERT Hybrid Discrete** (bin-based fusion)\n   - BERT4Rec + LightGCN with sequence-length adaptive fusion\n\n3. **TCN-BERT4Rec**\n   - Temporal Convolutional Networks + BERT4Rec\n   - Combines causal temporal patterns with bidirectional context\n\n4. **TGT-BERT4Rec** (NEW! ğŸš€)\n   - Temporal Graph Transformer + BERT4Rec\n   - Time-aware graph attention + bidirectional transformers\n   - **Target**: NDCG@10 > 0.82 (>7% improvement over baseline 0.7665)\n\n**Fine-Tuned Optimal Configuration:**\n- **d_model**: 64 (embedding dimension)\n- **n_heads**: 2 (attention heads)\n- **n_blocks**: 2 (transformer layers)\n- **Learning rate**: 0.001\n- **Dropout**: 0.2\n- **GNN layers**: 2 (for hybrid models)\n- **TGT fusion Î±**: 0.3 (learnable)\n\n**Training Settings:**\n- Max Epochs: 200 (with early stopping patience=20)\n- Batch size: 256\n- Expected convergence: epoch 40-60\n\n**Time Estimate: ~4-5 hours with GPU P100**\n\n---","metadata":{}},{"id":"1671035a","cell_type":"markdown","source":"## Step 1: Clone Repository","metadata":{}},{"id":"cebf276e","cell_type":"code","source":"# Clone repository\n!git clone https://github.com/faroukq1/length-adaptive.git\n\n# Change to project directory\n%cd length-adaptive\n\n# Verify structure\n!ls -lh experiments/\n\nprint(\"\\nâœ… Repository cloned successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c8298884","cell_type":"markdown","source":"## Step 2: Install Dependencies","metadata":{}},{"id":"70f5db7e","cell_type":"code","source":"# Install required packages\n!pip install -q torch-geometric tqdm scikit-learn pandas matplotlib seaborn\n\nprint(\"âœ… All dependencies installed successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"77559a84","cell_type":"markdown","source":"## Step 3: Verify GPU","metadata":{}},{"id":"3f16171f","cell_type":"code","source":"import torch\n\nprint(\"=\"*70)\nprint(\"ğŸ” GPU Information\")\nprint(\"=\"*70)\n\nif torch.cuda.is_available():\n    print(f\"âœ… GPU Available: {torch.cuda.get_device_name(0)}\")\n    print(f\"ğŸ’¾ Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n    print(f\"ğŸ”¢ CUDA Version: {torch.version.cuda}\")\nelse:\n    print(\"âŒ No GPU available - training will be slow!\")\n\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d7ac87ee","cell_type":"markdown","source":"## Step 4: Check Data Files\n\nThe repository should already contain preprocessed MovieLens-1M data.","metadata":{}},{"id":"b2d6cd84","cell_type":"code","source":"import os\n\ndata_file = 'data/ml-1m/processed/sequences.pkl'\ngraph_file = 'data/graphs/cooccurrence_graph.pkl'\n\nprint(\"=\"*70)\nprint(\"ğŸ” Checking Data Files\")\nprint(\"=\"*70)\n\nif os.path.exists(data_file):\n    print(f\"âœ… Sequential data found: {data_file}\")\n    print(f\"   Size: {os.path.getsize(data_file) / 1024 / 1024:.2f} MB\")\nelse:\n    print(f\"âŒ Sequential data NOT found: {data_file}\")\n    print(\"   You may need to run preprocessing first!\")\n\nif os.path.exists(graph_file):\n    print(f\"âœ… Graph data found: {graph_file}\")\n    print(f\"   Size: {os.path.getsize(graph_file) / 1024 / 1024:.2f} MB\")\nelse:\n    print(f\"âŒ Graph data NOT found: {graph_file}\")\n    print(\"   You may need to run graph construction first!\")\n\nprint(\"=\"*70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f6846f8c","cell_type":"markdown","source":"## Step 7: Run Experiments - TCN-BERT4Rec (NEW!)\n\nThird model: Temporal Convolutional Networks + BERT4Rec","metadata":{}},{"id":"a6f3f055","cell_type":"code","source":"# Run TCN-BERT4Rec\n!python experiments/run_best_models.py \\\n    --models tcn_bert4rec \\\n    --epochs 200 \\\n    --patience 20 \\\n    --eval_every 1 \\\n    --d_model 64 \\\n    --n_heads 2 \\\n    --n_blocks 2 \\\n    --tcn_channels 64 64 64 \\\n    --tcn_kernel_size 3 \\\n    --tcn_fusion learnable \\\n    --lr 0.001 \\\n    --batch_size 256 \\\n    --dropout 0.2\n\nprint(\"\\nâœ… TCN-BERT4Rec training complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ecf38ede","cell_type":"markdown","source":"## Step 8: Run Experiments - TGT-BERT4Rec (NEW! ğŸš€)\n\nFourth model: Temporal Graph Transformer + BERT4Rec  \n**Target: NDCG@10 > 0.82** (beating 0.7665 baseline by >7%)","metadata":{}},{"id":"0b7b5596","cell_type":"code","source":"# Run TGT-BERT4Rec\n!python experiments/run_best_models.py \\\n    --models tgt_bert4rec \\\n    --epochs 200 \\\n    --patience 20 \\\n    --eval_every 1 \\\n    --d_model 64 \\\n    --n_heads 2 \\\n    --n_blocks 2 \\\n    --tgt_fusion_alpha 0.3 \\\n    --tgt_learnable_fusion True \\\n    --lr 0.001 \\\n    --batch_size 256 \\\n    --dropout 0.2\n\nprint(\"\\nâœ… TGT-BERT4Rec training complete!\")\nprint(\"ğŸ“Š Check if NDCG@10 > 0.82 achieved!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"10a806fe","cell_type":"markdown","source":"## Step 5: Run Experiments - BERT Hybrid Fixed\n\nFirst model: BERT4Rec + LightGCN with fixed fusion (Î±=0.5)","metadata":{}},{"id":"d53c6f43","cell_type":"code","source":"# Run BERT Hybrid Fixed\n!python experiments/run_best_models.py \\\n    --models bert_hybrid_fixed \\\n    --epochs 200 \\\n    --patience 20 \\\n    --eval_every 1 \\\n    --d_model 64 \\\n    --n_heads 2 \\\n    --n_blocks 2 \\\n    --gnn_layers 2 \\\n    --fixed_alpha 0.5 \\\n    --lr 0.001 \\\n    --batch_size 256 \\\n    --dropout 0.2\n\nprint(\"\\nâœ… BERT Hybrid Fixed training complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d683e921","cell_type":"markdown","source":"## Step 6: Run Experiments - BERT Hybrid Discrete\n\nSecond model: BERT4Rec + LightGCN with discrete bin-based fusion","metadata":{}},{"id":"330df50f","cell_type":"code","source":"# Run BERT Hybrid Discrete\n!python experiments/run_best_models.py \\\n    --models bert_hybrid_discrete \\\n    --epochs 200 \\\n    --patience 20 \\\n    --eval_every 1 \\\n    --d_model 64 \\\n    --n_heads 2 \\\n    --n_blocks 2 \\\n    --gnn_layers 2 \\\n    --L_short 10 \\\n    --L_long 30 \\\n    --lr 0.001 \\\n    --batch_size 256 \\\n    --dropout 0.2\n\nprint(\"\\nâœ… BERT Hybrid Discrete training complete!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"08858db1","cell_type":"markdown","source":"## Step 10: Collect and Analyze Results","metadata":{}},{"id":"c719484f","cell_type":"code","source":"import json\nimport pandas as pd\nfrom pathlib import Path\nfrom datetime import datetime\n\n# Find all result directories\nresults_dir = Path('results')\nresult_dirs = sorted(results_dir.glob('*_202*'))\n\nprint(\"=\"*70)\nprint(\"ğŸ“Š Collecting Results\")\nprint(\"=\"*70)\nprint(f\"Found {len(result_dirs)} experiment(s)\\n\")\n\n# Collect results\nresults_data = []\n\nfor exp_dir in result_dirs:\n    results_file = exp_dir / 'results.json'\n    \n    if results_file.exists():\n        with open(results_file, 'r') as f:\n            data = json.load(f)\n        \n        model_name = exp_dir.name.rsplit('_', 2)[0]  # Extract model name\n        \n        results_data.append({\n            'Model': model_name,\n            'HR@10': data['test_metrics']['HR@10'],\n            'NDCG@10': data['test_metrics']['NDCG@10'],\n            'MRR@10': data['test_metrics']['MRR@10'],\n            'Best Epoch': data['best_epoch'],\n            'Directory': str(exp_dir)\n        })\n\n# Create DataFrame\nif results_data:\n    df = pd.DataFrame(results_data)\n    df = df.sort_values('NDCG@10', ascending=False)\n    \n    print(\"\\nğŸ“ˆ Results Summary:\")\n    print(\"=\"*70)\n    print(df[['Model', 'HR@10', 'NDCG@10', 'MRR@10', 'Best Epoch']].to_string(index=False))\n    print(\"=\"*70)\n    \n    # Save to CSV\n    csv_path = results_dir / 'best_models_summary.csv'\n    df.to_csv(csv_path, index=False)\n    print(f\"\\nğŸ’¾ Results saved to: {csv_path}\")\nelse:\n    print(\"âŒ No results found!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"43e0fb50","cell_type":"markdown","source":"## Step 11: Visualize Training History","metadata":{}},{"id":"be05e56d","cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Load training histories\nhistories = {}\n\nfor exp_dir in result_dirs:\n    history_file = exp_dir / 'history.json'\n    \n    if history_file.exists():\n        with open(history_file, 'r') as f:\n            history = json.load(f)\n        \n        model_name = exp_dir.name.rsplit('_', 2)[0]\n        histories[model_name] = history\n\n# Plot\nif histories:\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n    \n    # Training Loss\n    ax = axes[0, 0]\n    for model_name, history in histories.items():\n        ax.plot(history['train_loss'], label=model_name, linewidth=2)\n    ax.set_xlabel('Epoch', fontsize=12)\n    ax.set_ylabel('Training Loss', fontsize=12)\n    ax.set_title('Training Loss Curves', fontsize=14, fontweight='bold')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    \n    # Validation HR@10\n    ax = axes[0, 1]\n    for model_name, history in histories.items():\n        hr_values = [m['hr@10'] for m in history['val_metrics']]\n        ax.plot(hr_values, label=model_name, linewidth=2, marker='o', markersize=4, alpha=0.7)\n    ax.set_xlabel('Evaluation Step', fontsize=12)\n    ax.set_ylabel('HR@10', fontsize=12)\n    ax.set_title('Validation HR@10', fontsize=14, fontweight='bold')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    \n    # Validation NDCG@10\n    ax = axes[1, 0]\n    for model_name, history in histories.items():\n        ndcg_values = [m['ndcg@10'] for m in history['val_metrics']]\n        ax.plot(ndcg_values, label=model_name, linewidth=2, marker='s', markersize=4, alpha=0.7)\n    ax.set_xlabel('Evaluation Step', fontsize=12)\n    ax.set_ylabel('NDCG@10', fontsize=12)\n    ax.set_title('Validation NDCG@10', fontsize=14, fontweight='bold')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    \n    # Validation MRR\n    ax = axes[1, 1]\n    for model_name, history in histories.items():\n        mrr_values = [m['mrr'] for m in history['val_metrics']]\n        ax.plot(mrr_values, label=model_name, linewidth=2, marker='^', markersize=4, alpha=0.7)\n    ax.set_xlabel('Evaluation Step', fontsize=12)\n    ax.set_ylabel('MRR', fontsize=12)\n    ax.set_title('Validation MRR', fontsize=14, fontweight='bold')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('results/training_history.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(\"âœ… Visualizations created and saved!\")\nelse:\n    print(\"âŒ No training histories found!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a818d5b2","cell_type":"markdown","source":"## Step 12: Compare Models - Bar Charts","metadata":{}},{"id":"e507c440","cell_type":"code","source":"if results_data:\n    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n    \n    models = df['Model'].tolist()\n    x_pos = np.arange(len(models))\n    \n    # HR@10\n    ax = axes[0]\n    bars = ax.bar(x_pos, df['HR@10'], color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels(models, rotation=15, ha='right')\n    ax.set_ylabel('HR@10', fontsize=12)\n    ax.set_title('Hit Rate @ 10', fontsize=14, fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    # Add value labels on bars\n    for bar in bars:\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n    \n    # NDCG@10\n    ax = axes[1]\n    bars = ax.bar(x_pos, df['NDCG@10'], color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels(models, rotation=15, ha='right')\n    ax.set_ylabel('NDCG@10', fontsize=12)\n    ax.set_title('NDCG @ 10', fontsize=14, fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    for bar in bars:\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n    \n    # MRR@10\n    ax = axes[2]\n    bars = ax.bar(x_pos, df['MRR@10'], color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n    ax.set_xticks(x_pos)\n    ax.set_xticklabels(models, rotation=15, ha='right')\n    ax.set_ylabel('MRR@10', fontsize=12)\n    ax.set_title('Mean Reciprocal Rank @ 10', fontsize=14, fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='y')\n    \n    for bar in bars:\n        height = bar.get_height()\n        ax.text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n    \n    plt.tight_layout()\n    plt.savefig('results/model_comparison.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(\"âœ… Comparison charts created!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"96b8778b","cell_type":"markdown","source":"## Step 13: Download Results Package","metadata":{}},{"id":"03e65a79","cell_type":"code","source":"import shutil\n\n# Create zip file with all results\nprint(\"ğŸ“¦ Creating results package...\")\n\nzip_path = '/kaggle/working/best_models_results'\nshutil.make_archive(zip_path, 'zip', 'results')\n\nprint(f\"âœ… Results packaged: {zip_path}.zip\")\nprint(\"\\nğŸ“¥ Download this file to get:\")\nprint(\"  - All model checkpoints\")\nprint(\"  - Training histories\")\nprint(\"  - Test results\")\nprint(\"  - Visualizations\")\nprint(\"  - Summary CSV\")\n\n# List what's included\nprint(\"\\nğŸ“ Package contents:\")\n!ls -lh results/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ef81634a","cell_type":"markdown","source":"## Summary\n\n**Experiment Complete! ğŸ‰**\n\nThis notebook trained and evaluated four state-of-the-art models:\n\n1. âœ… **BERT Hybrid Fixed** - BERT4Rec + LightGCN with fixed fusion\n2. âœ… **BERT Hybrid Discrete** - BERT4Rec + LightGCN with adaptive fusion\n3. âœ… **TCN-BERT4Rec** - Temporal Convolutions + BERT4Rec\n4. âœ… **TGT-BERT4Rec** - Temporal Graph Transformer + BERT4Rec (ğŸš€ NEW!)\n\n**Key Features:**\n- ğŸ“Š Publication-quality results (200 epochs)\n- ğŸ“ˆ Comprehensive metrics (HR@10, NDCG@10, MRR)\n- ğŸ“‰ Training curve visualizations\n- ğŸ’¾ All checkpoints and results saved\n- ğŸ¯ **TGT Target**: NDCG@10 > 0.82 (>7% over baseline 0.7665)\n\n**TGT-BERT4Rec Highlights:**\n- Time-aware graph attention with timestamp encoding\n- Gated fusion (Î±=0.3, learnable) between TGT and BERT branches\n- Combines structural graph patterns with bidirectional sequences\n- Expected to achieve highest performance among all models\n\n**Next Steps:**\n- Analyze if TGT-BERT4Rec beat the target NDCG@10 > 0.82\n- Compare fusion weights across models\n- Test ablations (BERT-only vs TGT-only vs Hybrid)\n- Write the paper! ğŸ“","metadata":{}}]}