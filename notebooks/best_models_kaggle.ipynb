{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f50bbeb",
   "metadata": {},
   "source": [
    "# Best Models Training - BERT Hybrid + TCN + TGT\n",
    "## Publication-Quality Experiments on MovieLens-1M\n",
    "\n",
    "**Models to Train (4 Total):**\n",
    "\n",
    "1. **BERT Hybrid Fixed** (Î±=0.5)\n",
    "   - BERT4Rec + LightGCN with fixed fusion weight\n",
    "\n",
    "2. **BERT Hybrid Discrete** (bin-based fusion)\n",
    "   - BERT4Rec + LightGCN with sequence-length adaptive fusion\n",
    "\n",
    "3. **TCN-BERT4Rec**\n",
    "   - Temporal Convolutional Networks + BERT4Rec\n",
    "   - Combines causal temporal patterns with bidirectional context\n",
    "\n",
    "4. **TGT-BERT4Rec** (NEW! ğŸš€)\n",
    "   - Temporal Graph Transformer + BERT4Rec\n",
    "   - Time-aware graph attention + bidirectional transformers\n",
    "   - **Target**: NDCG@10 > 0.82 (>7% improvement over baseline 0.7665)\n",
    "\n",
    "**Fine-Tuned Optimal Configuration:**\n",
    "- **d_model**: 64 (embedding dimension)\n",
    "- **n_heads**: 2 (attention heads)\n",
    "- **n_blocks**: 2 (transformer layers)\n",
    "- **Learning rate**: 0.001\n",
    "- **Dropout**: 0.2\n",
    "- **GNN layers**: 2 (for hybrid models)\n",
    "- **TGT fusion Î±**: 0.3 (learnable)\n",
    "\n",
    "**Training Settings:**\n",
    "- Max Epochs: 200 (with early stopping patience=20)\n",
    "- Batch size: 256\n",
    "- Expected convergence: epoch 40-60\n",
    "\n",
    "**Time Estimate: ~4-5 hours with GPU P100**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1671035a",
   "metadata": {},
   "source": [
    "## Step 1: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebf276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/faroukq1/length-adaptive.git\n",
    "\n",
    "# Change to project directory\n",
    "%cd length-adaptive\n",
    "\n",
    "# Verify structure\n",
    "!ls -lh experiments/\n",
    "\n",
    "print(\"\\nâœ… Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8298884",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f5db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch-geometric tqdm scikit-learn pandas matplotlib seaborn\n",
    "\n",
    "print(\"âœ… All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77559a84",
   "metadata": {},
   "source": [
    "## Step 3: Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” GPU Information\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"ğŸ”¢ CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"âŒ No GPU available - training will be slow!\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ac87ee",
   "metadata": {},
   "source": [
    "## Step 4: Check Data Files\n",
    "\n",
    "The repository should already contain preprocessed MovieLens-1M data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d6cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_file = 'data/ml-1m/processed/sequences.pkl'\n",
    "graph_file = 'data/graphs/cooccurrence_graph.pkl'\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” Checking Data Files\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if os.path.exists(data_file):\n",
    "    print(f\"âœ… Sequential data found: {data_file}\")\n",
    "    print(f\"   Size: {os.path.getsize(data_file) / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    print(f\"âŒ Sequential data NOT found: {data_file}\")\n",
    "    print(\"   You may need to run preprocessing first!\")\n",
    "\n",
    "if os.path.exists(graph_file):\n",
    "    print(f\"âœ… Graph data found: {graph_file}\")\n",
    "    print(f\"   Size: {os.path.getsize(graph_file) / 1024 / 1024:.2f} MB\")\n",
    "else:\n",
    "    print(f\"âŒ Graph data NOT found: {graph_file}\")\n",
    "    print(\"   You may need to run graph construction first!\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a806fe",
   "metadata": {},
   "source": [
    "## Step 5: Run Experiments - BERT Hybrid Fixed\n",
    "\n",
    "First model: BERT4Rec + LightGCN with fixed fusion (Î±=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c6f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run BERT Hybrid Fixed\n",
    "!python experiments/run_best_models.py \\\n",
    "    --models bert_hybrid_fixed \\\n",
    "    --epochs 200 \\\n",
    "    --patience 20 \\\n",
    "    --eval_every 5 \\\n",
    "    --d_model 64 \\\n",
    "    --n_heads 2 \\\n",
    "    --n_blocks 2 \\\n",
    "    --gnn_layers 2 \\\n",
    "    --fixed_alpha 0.5 \\\n",
    "    --lr 0.001 \\\n",
    "    --batch_size 256 \\\n",
    "    --dropout 0.2\n",
    "\n",
    "print(\"\\nâœ… BERT Hybrid Fixed training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683e921",
   "metadata": {},
   "source": [
    "## Step 6: Run Experiments - BERT Hybrid Discrete\n",
    "\n",
    "Second model: BERT4Rec + LightGCN with discrete bin-based fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330df50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run BERT Hybrid Discrete\n",
    "!python experiments/run_best_models.py \\\n",
    "    --models bert_hybrid_discrete \\\n",
    "    --epochs 200 \\\n",
    "    --patience 20 \\\n",
    "    --eval_every 5 \\\n",
    "    --d_model 64 \\\n",
    "    --n_heads 2 \\\n",
    "    --n_blocks 2 \\\n",
    "    --gnn_layers 2 \\\n",
    "    --L_short 10 \\\n",
    "    --L_long 30 \\\n",
    "    --lr 0.001 \\\n",
    "    --batch_size 256 \\\n",
    "    --dropout 0.2\n",
    "\n",
    "print(\"\\nâœ… BERT Hybrid Discrete training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6846f8c",
   "metadata": {},
   "source": [
    "## Step 7: Run Experiments - TCN-BERT4Rec (NEW!)\n",
    "\n",
    "Third model: Temporal Convolutional Networks + BERT4Rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f3f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TCN-BERT4Rec\n",
    "!python experiments/run_best_models.py \\\n",
    "    --models tcn_bert4rec \\\n",
    "    --epochs 200 \\\n",
    "    --patience 20 \\\n",
    "    --eval_every 5 \\\n",
    "    --d_model 64 \\\n",
    "    --n_heads 2 \\\n",
    "    --n_blocks 2 \\\n",
    "    --tcn_channels 64 64 64 \\\n",
    "    --tcn_kernel_size 3 \\\n",
    "    --tcn_fusion learnable \\\n",
    "    --lr 0.001 \\\n",
    "    --batch_size 256 \\\n",
    "    --dropout 0.2\n",
    "\n",
    "print(\"\\nâœ… TCN-BERT4Rec training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38ede",
   "metadata": {},
   "source": [
    "## Step 8: Run Experiments - TGT-BERT4Rec (NEW! ğŸš€)\n",
    "\n",
    "Fourth model: Temporal Graph Transformer + BERT4Rec  \n",
    "**Target: NDCG@10 > 0.82** (beating 0.7665 baseline by >7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7b5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TGT-BERT4Rec\n",
    "!python experiments/run_best_models.py \\\n",
    "    --models tgt_bert4rec \\\n",
    "    --epochs 200 \\\n",
    "    --patience 20 \\\n",
    "    --eval_every 5 \\\n",
    "    --d_model 64 \\\n",
    "    --n_heads 2 \\\n",
    "    --n_blocks 2 \\\n",
    "    --tgt_fusion_alpha 0.3 \\\n",
    "    --tgt_learnable_fusion True \\\n",
    "    --lr 0.001 \\\n",
    "    --batch_size 256 \\\n",
    "    --dropout 0.2\n",
    "\n",
    "print(\"\\nâœ… TGT-BERT4Rec training complete!\")\n",
    "print(\"ğŸ“Š Check if NDCG@10 > 0.82 achieved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08858db1",
   "metadata": {},
   "source": [
    "## Step 10: Collect and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Find all result directories\n",
    "results_dir = Path('results')\n",
    "result_dirs = sorted(results_dir.glob('*_202*'))\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š Collecting Results\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Found {len(result_dirs)} experiment(s)\\n\")\n",
    "\n",
    "# Collect results\n",
    "results_data = []\n",
    "\n",
    "for exp_dir in result_dirs:\n",
    "    results_file = exp_dir / 'results.json'\n",
    "    \n",
    "    if results_file.exists():\n",
    "        with open(results_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        model_name = exp_dir.name.rsplit('_', 2)[0]  # Extract model name\n",
    "        \n",
    "        results_data.append({\n",
    "            'Model': model_name,\n",
    "            'HR@10': data['test_metrics']['HR@10'],\n",
    "            'NDCG@10': data['test_metrics']['NDCG@10'],\n",
    "            'MRR@10': data['test_metrics']['MRR@10'],\n",
    "            'Best Epoch': data['best_epoch'],\n",
    "            'Directory': str(exp_dir)\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "if results_data:\n",
    "    df = pd.DataFrame(results_data)\n",
    "    df = df.sort_values('NDCG@10', ascending=False)\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ Results Summary:\")\n",
    "    print(\"=\"*70)\n",
    "    print(df[['Model', 'HR@10', 'NDCG@10', 'MRR@10', 'Best Epoch']].to_string(index=False))\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = results_dir / 'best_models_summary.csv'\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nğŸ’¾ Results saved to: {csv_path}\")\n",
    "else:\n",
    "    print(\"âŒ No results found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e0fb50",
   "metadata": {},
   "source": [
    "## Step 11: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load training histories\n",
    "histories = {}\n",
    "\n",
    "for exp_dir in result_dirs:\n",
    "    history_file = exp_dir / 'history.json'\n",
    "    \n",
    "    if history_file.exists():\n",
    "        with open(history_file, 'r') as f:\n",
    "            history = json.load(f)\n",
    "        \n",
    "        model_name = exp_dir.name.rsplit('_', 2)[0]\n",
    "        histories[model_name] = history\n",
    "\n",
    "# Plot\n",
    "if histories:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Training Loss\n",
    "    ax = axes[0, 0]\n",
    "    for model_name, history in histories.items():\n",
    "        ax.plot(history['train_loss'], label=model_name, linewidth=2)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Training Loss', fontsize=12)\n",
    "    ax.set_title('Training Loss Curves', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation HR@10\n",
    "    ax = axes[0, 1]\n",
    "    for model_name, history in histories.items():\n",
    "        hr_values = [m['hr@10'] for m in history['val_metrics']]\n",
    "        ax.plot(hr_values, label=model_name, linewidth=2, marker='o', markersize=4, alpha=0.7)\n",
    "    ax.set_xlabel('Evaluation Step', fontsize=12)\n",
    "    ax.set_ylabel('HR@10', fontsize=12)\n",
    "    ax.set_title('Validation HR@10', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation NDCG@10\n",
    "    ax = axes[1, 0]\n",
    "    for model_name, history in histories.items():\n",
    "        ndcg_values = [m['ndcg@10'] for m in history['val_metrics']]\n",
    "        ax.plot(ndcg_values, label=model_name, linewidth=2, marker='s', markersize=4, alpha=0.7)\n",
    "    ax.set_xlabel('Evaluation Step', fontsize=12)\n",
    "    ax.set_ylabel('NDCG@10', fontsize=12)\n",
    "    ax.set_title('Validation NDCG@10', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation MRR\n",
    "    ax = axes[1, 1]\n",
    "    for model_name, history in histories.items():\n",
    "        mrr_values = [m['mrr'] for m in history['val_metrics']]\n",
    "        ax.plot(mrr_values, label=model_name, linewidth=2, marker='^', markersize=4, alpha=0.7)\n",
    "    ax.set_xlabel('Evaluation Step', fontsize=12)\n",
    "    ax.set_ylabel('MRR', fontsize=12)\n",
    "    ax.set_title('Validation MRR', fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Visualizations created and saved!\")\n",
    "else:\n",
    "    print(\"âŒ No training histories found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a818d5b2",
   "metadata": {},
   "source": [
    "## Step 12: Compare Models - Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_data:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    models = df['Model'].tolist()\n",
    "    x_pos = np.arange(len(models))\n",
    "    \n",
    "    # HR@10\n",
    "    ax = axes[0]\n",
    "    bars = ax.bar(x_pos, df['HR@10'], color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(models, rotation=15, ha='right')\n",
    "    ax.set_ylabel('HR@10', fontsize=12)\n",
    "    ax.set_title('Hit Rate @ 10', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # NDCG@10\n",
    "    ax = axes[1]\n",
    "    bars = ax.bar(x_pos, df['NDCG@10'], color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(models, rotation=15, ha='right')\n",
    "    ax.set_ylabel('NDCG@10', fontsize=12)\n",
    "    ax.set_title('NDCG @ 10', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    # MRR\n",
    "    ax = axes[2]\n",
    "    bars = ax.bar(x_pos, df['MRR'], color=['#FF6B6B', '#4ECDC4', '#45B7D1'], alpha=0.8)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(models, rotation=15, ha='right')\n",
    "    ax.set_ylabel('MRR', fontsize=12)\n",
    "    ax.set_title('Mean Reciprocal Rank', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Comparison charts created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8778b",
   "metadata": {},
   "source": [
    "## Step 13: Download Results Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e65a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Create zip file with all results\n",
    "print(\"ğŸ“¦ Creating results package...\")\n",
    "\n",
    "zip_path = '/kaggle/working/best_models_results'\n",
    "shutil.make_archive(zip_path, 'zip', 'results')\n",
    "\n",
    "print(f\"âœ… Results packaged: {zip_path}.zip\")\n",
    "print(\"\\nğŸ“¥ Download this file to get:\")\n",
    "print(\"  - All model checkpoints\")\n",
    "print(\"  - Training histories\")\n",
    "print(\"  - Test results\")\n",
    "print(\"  - Visualizations\")\n",
    "print(\"  - Summary CSV\")\n",
    "\n",
    "# List what's included\n",
    "print(\"\\nğŸ“ Package contents:\")\n",
    "!ls -lh results/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef81634a",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Experiment Complete! ğŸ‰**\n",
    "\n",
    "This notebook trained and evaluated four state-of-the-art models:\n",
    "\n",
    "1. âœ… **BERT Hybrid Fixed** - BERT4Rec + LightGCN with fixed fusion\n",
    "2. âœ… **BERT Hybrid Discrete** - BERT4Rec + LightGCN with adaptive fusion\n",
    "3. âœ… **TCN-BERT4Rec** - Temporal Convolutions + BERT4Rec\n",
    "4. âœ… **TGT-BERT4Rec** - Temporal Graph Transformer + BERT4Rec (ğŸš€ NEW!)\n",
    "\n",
    "**Key Features:**\n",
    "- ğŸ“Š Publication-quality results (200 epochs)\n",
    "- ğŸ“ˆ Comprehensive metrics (HR@10, NDCG@10, MRR)\n",
    "- ğŸ“‰ Training curve visualizations\n",
    "- ğŸ’¾ All checkpoints and results saved\n",
    "- ğŸ¯ **TGT Target**: NDCG@10 > 0.82 (>7% over baseline 0.7665)\n",
    "\n",
    "**TGT-BERT4Rec Highlights:**\n",
    "- Time-aware graph attention with timestamp encoding\n",
    "- Gated fusion (Î±=0.3, learnable) between TGT and BERT branches\n",
    "- Combines structural graph patterns with bidirectional sequences\n",
    "- Expected to achieve highest performance among all models\n",
    "\n",
    "**Next Steps:**\n",
    "- Analyze if TGT-BERT4Rec beat the target NDCG@10 > 0.82\n",
    "- Compare fusion weights across models\n",
    "- Test ablations (BERT-only vs TGT-only vs Hybrid)\n",
    "- Write the paper! ğŸ“"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
